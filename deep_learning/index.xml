<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Machine(Deep) Learning on Anthony&#39;s Blogs</title>
    <link>https://anthony-tan.com/deep_learning/</link>
    <description>Recent content in Machine(Deep) Learning on Anthony&#39;s Blogs</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://anthony-tan.com/deep_learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Least Squares Estimation</title>
      <link>https://anthony-tan.com/Least-Squares-Estimation/</link>
      <pubDate>Fri, 14 Feb 2020 11:33:36 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Least-Squares-Estimation/</guid>
      <description>Priliminaries A Simple Linear Regression the column space  Another Example of Linear Regression 1 In the blog A Simple Linear Regression, squares of the difference between the output of a predictor and the target were used as a loss function in a regression problem. And it could be also written as:
\[ \ell(\hat{\mathbf{y}}_i,\mathbf{y}_i)=(\hat{\mathbf{y}}_i-\mathbf{y}_i)^T(\hat{\mathbf{y}}_i-\mathbf{y}_i) \tag{1} \]
The linear regression model in a matrix form is:
\[ y=\mathbf{w}^T\mathbf{x}+\mathbf{b}\tag{2} \]
What we do in this post is analyze the least-squares methods from two different viewpoints</description>
    </item>
    
    <item>
      <title>A Simple Linear Regression</title>
      <link>https://anthony-tan.com/A-Simple-Linear-Regression/</link>
      <pubDate>Fri, 11 Oct 2019 20:35:27 +0000</pubDate>
      
      <guid>https://anthony-tan.com/A-Simple-Linear-Regression/</guid>
      <description>Preliminaries Linear Algebra(the concepts of space, vector) Calculus An Introduction to Linear Regression  Notations of Linear Regression1 We have already created a simple linear model in the post “An Introduction to Linear Regression”. According to the definition of linearity, we can develop the simplest linear regression model:
\[ Y\sim w_1X+w_0\tag{1} \]
where the symbol \(\sim\) is read as “is approximately modeled as”. Equation (1) can also be described as “regressing \(Y\) on \(X\)(or \(Y\) onto \(X\))”.</description>
    </item>
    
    <item>
      <title>An Introduction to Linear Regression</title>
      <link>https://anthony-tan.com/An-Introduction-to-Linear-Regression/</link>
      <pubDate>Wed, 09 Oct 2019 18:36:40 +0000</pubDate>
      
      <guid>https://anthony-tan.com/An-Introduction-to-Linear-Regression/</guid>
      <description>Preliminariess Linear Algebra(the concepts of space, vector) Calculus  What is Linear Regression Linear regression is a basic idea in statistical and machine learning based on the linear combination. And it was usually used to predict some responses to some inputs(predictors).
Machine Learning and Statistical Learning Machine learning and statistical learning are similar but have some distinctions. In machine learning, models, regression models, or classification models, are used to predict the outputs of the new incoming inputs.</description>
    </item>
    
  </channel>
</rss>

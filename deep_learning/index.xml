<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Deep Learning on Anthony&#39;s Blogs</title>
    <link>https://anthony-tan.com/deep_learning/</link>
    <description>Recent content in Deep Learning on Anthony&#39;s Blogs</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="https://anthony-tan.com/deep_learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Drawbacks of Backpropagation</title>
      <link>https://anthony-tan.com/Drawbacks-of-Backpropagation/</link>
      <pubDate>Tue, 07 Jan 2020 10:14:53 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Drawbacks-of-Backpropagation/</guid>
      <description>Preliminaries ‘An Introduction to Backpropagation and Multilayer Perceptrons’ ‘The Backpropagation Algorithm’  Speed Backpropagation up 1 BP algorithm has been described in ‘An Introduction to Backpropagation and Multilayer Perceptrons’. And the implementation of the BP algorithm has been recorded at ‘The Backpropagation Algorithm’. BP has worked in many applications for many years, but there are too many drawbacks in the process. The basic BP algorithm is too slow for most practical applications that it might take days or even weeks in training.</description>
    </item>
    
    <item>
      <title>Backpropagation, Batch Training, and Incremental Training</title>
      <link>https://anthony-tan.com/Backpropagation-Batch-Training-and-Incremental-Training/</link>
      <pubDate>Thu, 02 Jan 2020 17:49:55 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Backpropagation-Batch-Training-and-Incremental-Training/</guid>
      <description>Preliminaries Calculus 1,2 Linear Algebra  Batch v.s. Incremental Training1 In both LMS and BP algorithms, the error in each update process step is not MSE but SE \(e=t_i-a_i\) which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set.</description>
    </item>
    
    <item>
      <title>The Backpropagation Algorithm</title>
      <link>https://anthony-tan.com/The-Backpropagation-Algorithm/</link>
      <pubDate>Wed, 01 Jan 2020 14:26:55 +0000</pubDate>
      
      <guid>https://anthony-tan.com/The-Backpropagation-Algorithm/</guid>
      <description>Preliminaries An Introduction to Backpropagation and Multilayer Perceptrons Culculus 1,2 Linear algebra Jacobian matrix  Architecture and Notations1 We have seen a three-layer network is flexible in approximating functions(An Introduction to Backpropagation and Multilayer Perceptrons). If we had a more-than-three-layer network, it could be used to approximate any functions as accurately as we want. However, another trouble that came to us is the learning rules. This problem almost killed neural networks in the 1970s.</description>
    </item>
    
    <item>
      <title>An Introduction to Backpropagation and Multilayer Perceptrons</title>
      <link>https://anthony-tan.com/An-Introduction-to-Backpropagation-and-Multilayer-Perceptrons/</link>
      <pubDate>Tue, 31 Dec 2019 10:29:33 +0000</pubDate>
      
      <guid>https://anthony-tan.com/An-Introduction-to-Backpropagation-and-Multilayer-Perceptrons/</guid>
      <description>Preliminaries Performance learning Perceptron learning rule Supervised Hebbian learning LMS  Form LMS to Backpropagation1 The LMS algorithm is a kind of ‘performance learning’. And we have studied several learning rules(algorithms) till now, such as ‘Perceptron learning rule’ and ‘Supervised Hebbian learning’. And they were based on the idea of the physical mechanism of biological neuron networks.
Then performance learning was represented. Because of its outstanding performance, we go further and further away from natural intelligence into performance learning.</description>
    </item>
    
    <item>
      <title>Widrow-Hoff Learning</title>
      <link>https://anthony-tan.com/Widrow-Hoff-Learning/</link>
      <pubDate>Mon, 23 Dec 2019 18:51:59 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Widrow-Hoff-Learning/</guid>
      <description>Preliminaries ‘Performance Surfaces and Optimum Points’ Linear algebra stochastic approximation Probability Theory  ADALINE, LMS, and Widrow-Hoff learning1 Performance learning had been discussed. But we have not used it in any neural network. In this post, we talk about an important application of performance learning. And this new neural network was invented by Frank Widrow and his graduate student Marcian Hoff in 1960. It was almost the same time as Perceptron was developed which had been discussed in ‘Perceptron Learning Rule’.</description>
    </item>
    
    <item>
      <title>Conjugate Gradient</title>
      <link>https://anthony-tan.com/Conjugate-Gradient/</link>
      <pubDate>Sat, 21 Dec 2019 13:40:24 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Conjugate-Gradient/</guid>
      <description>Preliminaries ‘steepest descent method’ “Newton’s method”  Conjugate Gradient1 We have learned ‘steepest descent method’ and “Newton’s method”. The main advantage of Newton’s method is the speed, it converges quickly. And the main advantage of the steepest descent method guarantees to converge to a local minimum. But the limit of Newton’s method is that it needs too many resources for both computation and storage when the number of parameters is large.</description>
    </item>
    
    <item>
      <title>Newton&#39;s Method</title>
      <link>https://anthony-tan.com/Newton_s-Method/</link>
      <pubDate>Sat, 21 Dec 2019 11:39:56 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Newton_s-Method/</guid>
      <description>Preliminaries ‘steepest descent algorithm’ Linear Algebra Calculus 1,2  Newton’s Method1 Taylor series gives us the conditions for minimum points based on both first-order items and the second-order item. And first-order item approximation of a performance index function produced a powerful algorithm for locating the minimum points which we call ‘steepest descent algorithm’.
Now we want to have an insight into the second-order approximation of a function to find out whether there is an algorithm that can also work as a guide to the minimum points.</description>
    </item>
    
    <item>
      <title>Steepest Descent Method</title>
      <link>https://anthony-tan.com/Steepest-Descent-Method/</link>
      <pubDate>Fri, 20 Dec 2019 11:39:19 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Steepest-Descent-Method/</guid>
      <description>Preliminaries ‘An Introduction to Performance Optimization’ Linear algebra Calculus 1,2  Direction Based Algorithm and a Variation1 This post describes a direction searching algorithm(\(\mathbf{x}_{k}\)). And its variation gives a way to estimate step length (\(\alpha_k\)).
Steepest Descent To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill.</description>
    </item>
    
    <item>
      <title>An Introduction to Performance Optimization</title>
      <link>https://anthony-tan.com/An-Introduction-to-Performance-Optimization/</link>
      <pubDate>Fri, 20 Dec 2019 11:38:50 +0000</pubDate>
      
      <guid>https://anthony-tan.com/An-Introduction-to-Performance-Optimization/</guid>
      <description>Preliminaries Nothing  Performance Optimization1 Taylor series had been used for analyzing the performance surface and locating the optimum points of a certain performance index. This short post is a brief introduction to performance optimization and the following posts are the samples of three optimization algorithms categories:
‘Steepest Descent’ “Newton’s Method” ‘Conjugate Gradient’  Recall the analysis of the performance index, which is a function of the parameters of the model.</description>
    </item>
    
    <item>
      <title>Quadratic Functions</title>
      <link>https://anthony-tan.com/Quadratic-Functions/</link>
      <pubDate>Thu, 19 Dec 2019 15:45:37 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Quadratic-Functions/</guid>
      <description>Preliminaries Linear algebra Calculus 1,2 Taylor series  Quadratic Functions1 Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.
\[ F(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}+\mathbf{d}\mathbf{x}+c\tag{1} \]
where \(A\) is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:
\[ \nabla (\mathbf{h}^T\mathbf{x})=\nabla (\mathbf{x}^T\mathbf{h})=\mathbf{h}\tag{2} \]
and
\[ \nabla (\mathbf{x}^TQ\mathbf{x})=Q\mathbf{x}+Q^T\mathbf{x}=2Q\mathbf{x}\tag{3} \]</description>
    </item>
    
    <item>
      <title>Performance Surfaces and Optimum Points</title>
      <link>https://anthony-tan.com/Performance-Surfaces-and-Optimum-Points/</link>
      <pubDate>Thu, 19 Dec 2019 08:57:53 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Performance-Surfaces-and-Optimum-Points/</guid>
      <description>Preliminaries Perceptron learning algorithm Hebbian learning algorithm Linear algebra  Neural Network Training Technique1 Several architectures of the neural networks had been introduced. And each neural network had its own learning rule, like, the perceptron learning algorithm, and the Hebbian learning algorithm. When more and more neural network architectures were designed, some general training methods were necessary. Up to now, we can classify all training rules in three categories in a general way:</description>
    </item>
    
    <item>
      <title>Supervised Hebbian Learning</title>
      <link>https://anthony-tan.com/Supervised-Hebbian-Learning/</link>
      <pubDate>Tue, 17 Dec 2019 18:24:40 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Supervised-Hebbian-Learning/</guid>
      <description>Preliminaries Linear algebra  Hebb Rule1 Hebb rule is one of the earliest neural network learning laws. It was published in 1949 by Donald O. Hebb, a Canadian psychologist, in his work ’ The Organization of Behavior’. In this great book, he proposed a possible mechanism for synaptic modification in the brain. And this rule then was used in training the artificial neural networks for pattern recognition.
’ The Organization of Behavior’ The main premise of the book is that behavior could be explained by the action of a neuron.</description>
    </item>
    
    <item>
      <title>Implement of Perceptron</title>
      <link>https://anthony-tan.com/Implement-of-Perceptron/</link>
      <pubDate>Thu, 12 Dec 2019 13:10:28 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Implement-of-Perceptron/</guid>
      <description>Preliminaries An Introduction to Neural Networks Neuron Model and Network Architecture Perceptron Learning Rule  Implement of Perceptron1 What we need to do next is to implement the algorithm described in ‘Perceptron Learning Rule’ and observe the effect of 1. different parameters, 2. different training sets, 3. and different transfer functions.
A single neuron perceptron consists of a linear combination and a threshold operation simply. So we note its capacity is close to a linear classification.</description>
    </item>
    
    <item>
      <title>Learning Rules and Perceptron Learning Rule</title>
      <link>https://anthony-tan.com/Learning-Rules-and-Perceptron-Learning-Rule/</link>
      <pubDate>Wed, 11 Dec 2019 21:30:42 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Learning-Rules-and-Perceptron-Learning-Rule/</guid>
      <description>Preliminaries supervised learning unsupervised learning reinforcement learning ‘An Introduction to Neural Networks’  Learning Rules1 We have built some neural network models in the post ‘An Introduction to Neural Networks’ and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures.</description>
    </item>
    
    <item>
      <title>Neuron Model and Network Architecture</title>
      <link>https://anthony-tan.com/Neuron-Model-and-Network-Architecture/</link>
      <pubDate>Tue, 10 Dec 2019 10:54:57 +0000</pubDate>
      
      <guid>https://anthony-tan.com/Neuron-Model-and-Network-Architecture/</guid>
      <description>Preliminaries linear classifier An Introduction to Neural Networks  Theory and Notation1 We are not able to build any artificial cells up to now. It seems impossible to build a neuron network through biological materials manually, either. To investigate the ability of neurons we have built mathematical models of the neuron. These models have been assigned a number of neuron-like properties. However, there must be a balance between the number of properties contained by the mathematical models and the current computational abilities of the machines.</description>
    </item>
    
    <item>
      <title>An Introduction to Neural Networks</title>
      <link>https://anthony-tan.com/An-Introduction-to-Neural-Networks/</link>
      <pubDate>Sun, 08 Dec 2019 19:01:32 +0000</pubDate>
      
      <guid>https://anthony-tan.com/An-Introduction-to-Neural-Networks/</guid>
      <description>Preliminaries Nothing  Neural Networks1 Neural Networks are a model of our brain that is built with neurons and is considered the source of intelligence. There are almost \(10^{11}\) neurons in the human brain and \(10^4\) connections of each neuron to other neurons. Some of these brilliant structures were given when we were born. Some other structures could be established by experience, and this progress is called learning. Learning is also considered as the establishment or modification of the connections between neurons.</description>
    </item>
    
  </channel>
</rss>

<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Learning Rules and Perceptron Learning Rule | Anthony's Blogs</title><meta name=keywords content="Artificial Neural Networks,Artificial Intelligence,perceptron learning rule,Learning Rules,Multiple-Neuron Perceptron,Perceptron Architecture"><meta name=description content="Preliminaries supervised learning unsupervised learning reinforcement learning ‘An Introduction to Neural Networks’  Learning Rules1 We have built some neural network models in the post ‘An Introduction to Neural Networks’ and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures."><meta name=author content="Anthony Tan"><link rel=canonical href=https://anthony-tan.com/Learning-Rules-and-Perceptron-Learning-Rule/><link crossorigin=anonymous href=../assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://anthony-tan.com/logo.png><link rel=apple-touch-icon href=https://anthony-tan.com/logo.png><link rel=mask-icon href=https://anthony-tan.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-12","auto"),ga("send","pageview"))</script><meta property="og:title" content="Learning Rules and Perceptron Learning Rule"><meta property="og:description" content="Preliminaries supervised learning unsupervised learning reinforcement learning ‘An Introduction to Neural Networks’  Learning Rules1 We have built some neural network models in the post ‘An Introduction to Neural Networks’ and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures."><meta property="og:type" content="article"><meta property="og:url" content="https://anthony-tan.com/Learning-Rules-and-Perceptron-Learning-Rule/"><meta property="article:section" content="deep_learning"><meta property="article:published_time" content="2019-12-11T21:30:42+00:00"><meta property="article:modified_time" content="2022-05-03T10:39:43+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Learning Rules and Perceptron Learning Rule"><meta name=twitter:description content="Preliminaries supervised learning unsupervised learning reinforcement learning ‘An Introduction to Neural Networks’  Learning Rules1 We have built some neural network models in the post ‘An Introduction to Neural Networks’ and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Deep Learning","item":"https://anthony-tan.com/deep_learning/"},{"@type":"ListItem","position":3,"name":"Learning Rules and Perceptron Learning Rule","item":"https://anthony-tan.com/Learning-Rules-and-Perceptron-Learning-Rule/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Learning Rules and Perceptron Learning Rule","name":"Learning Rules and Perceptron Learning Rule","description":"Preliminaries supervised learning unsupervised learning reinforcement learning ‘An Introduction to Neural Networks’  Learning Rules1 We have built some neural network models in the post ‘An Introduction to Neural Networks’ and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures.","keywords":["Artificial Neural Networks","Artificial Intelligence","perceptron learning rule","Learning Rules","Multiple-Neuron Perceptron","Perceptron Architecture"],"articleBody":"Preliminaries supervised learning unsupervised learning reinforcement learning ‘An Introduction to Neural Networks’  Learning Rules1 We have built some neural network models in the post ‘An Introduction to Neural Networks’ and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures.\nThe learning rule is a procedure to modify weights, bias, and other parameters in the model to perform a certain task. There are generally 3 types of learning rules:\nSupervised Learning   There is a training set of the model that contains a number of input data as well as correct output values that are also known as targets, like the set \\(\\{\\mathbf{p}_1,t_1\\},\\{\\mathbf{p}_2,t_2\\},\\cdots,\\{\\mathbf{p}_Q,t_Q\\},\\) where \\(\\mathbf{p}_i\\) (for \\(i) is the input of the model and \\(t_i\\)(for \\(i) is the corresponding target(any kind of output, like labels, regression values) the whole process is:  where target and current output are used to modify the neuron network to produce an output as close to the target as possible according to the input.  Unsupervised Learning   Unlike supervised learning, unsupervised learning doesn’t know the correct output at all, in other words, what the neuron network knows is only the inputs, and how to modify the parameters in the model is depend only on the inputs. This kind of learning is always used to perform clustering operations or vector quantization.   Reinforcement learning   it is another learning rule which is more like supervised learning and works more like a biological brain. there is no correct target as well but there is a grade to measure the performance of the network over some sequence of input.   Perceptron Architecture A perceptron is an easy model of a neuron, and what we are interested in is how to design a learning rule or develop a certain algorithm to make a perceptron possible to classify input signals. Perceptron is the easiest neuron model, and it is a good basis for more complex networks.\nIn a perceptron, it has weights, biases, and transfer functions. These are basic components of a neuron model. However, the transfer function here is specialized as a ‘hard limit function’\n\\[ f(x) = \\begin{cases} 0\u0026 \\text{ if } xand abbreviated notation with a layer of \\(S\\) neuron network is:\nwhere \\(W\\) are the weight matrix of \\(S\\) perceptrons. And each row of the matrix contains all the weight of a perceptron.\nSingle-Neuron Perceptron In some simple models, we can visualize a line or a plane named ‘decision boundary’ which is determined by the input vectors who make the input of its transfer function \\(n=0\\). For instance, in a 2-dimensional linear classification task, we were asked to find a line that can separate the input points into two different classes. This line here acts as a decision boundary and all the points on the line would produce \\(0\\) output through the linear model.\nLet’s start to study with one perceptron.\nIts decision boundary is the line:\n\\[ n=w_{1,1}p_1+w_{1,2}p_2+b=0\\tag{2} \\]\nFor example, when \\(w_{1,1}=1\\), \\(w_{1,2}=1\\) and \\(b=-1\\), we get the decision boundary:\n\\[ p_1+p_2-1=0\\tag{3} \\]\nfrom the figure, we can conclude the weight vector has the following properties:\n\\(W\\) always points to the purple region where \\(n=w_{1,1}p_1+w_{1,2}p_2+b0\\) The relation of \\(W\\) and the direction of the decision boundary is orthogonality.  Can this simple example perform some task? Of course. If we test the input \\(\\mathbf{p}_1=\\begin{bmatrix}0\u00260\\end{bmatrix}^T,\\mathbf{p}_1=\\begin{bmatrix}0\u00261\\end{bmatrix}^T,\\mathbf{p}_1=\\begin{bmatrix}1\u00260\\end{bmatrix}^T,\\mathbf{p}_1=\\begin{bmatrix}1\u00261\\end{bmatrix}^T\\) respectively, we could get \\(a_1=0,a_2=0,a_3=0,a_4=1\\). This is the ‘and’ operation in logical calculation.\n   input output     \\(\\begin{bmatrix}0\u00260\\end{bmatrix}^T\\) \\(0\\)   \\(\\begin{bmatrix}0\u00261\\end{bmatrix}^T\\) \\(0\\)   \\(\\begin{bmatrix}1\u00260\\end{bmatrix}^T\\) \\(0\\)   \\(\\begin{bmatrix}1\u00261\\end{bmatrix}^T\\) \\(1\\)    Multiple-Neuron Perceptron A multiple neuron perceptron is just a combination of some perceptrons, whose weight matrix \\(W\\) has multiple rows. And the transpose of row \\(i\\) of the \\(W\\) is notated as \\(_iW\\)(column form of the \\(i\\)th row in \\(W\\)) then the \\(i\\) th neuron has the decision boundary:\n\\[ _iW^T\\mathbf{p}+b_i=0\\tag{4} \\]\nFor the property of hard limit function that the output could just be one of \\(\\{0,1\\}\\). And for \\(S\\) neurons, there are at most \\(2^S\\) categories, that is to say to a \\(S\\) neuron perceptron in one layer it is impossible to solve the problems containing more than \\(2^S\\) classes.\nPerceptron Learning Rule Perceptron learning rule here is a kind of supervised learning rule. Recall some results above: 1. supervised learning had both input and corresponding correct target. 2. target, the output produced by the current model, and input produced the information on how to modify the model 3. \\(W\\) always points to the region where the output is \\(a=1\\)\nConstructing Learning Rules With the above results we try to design the rule and assume training dates are:\n\\[ \\{\\begin{bmatrix}1\\\\2\\end{bmatrix},1\\},\\{\\begin{bmatrix}-1\\\\2\\end{bmatrix},0\\},\\{\\begin{bmatrix}0\\\\-1\\end{bmatrix},0\\}\\tag{5} \\]\nAssigning Some Initial Values To modify the model, we need the output which is produced by the weights and input. And for this supervised learning algorithm we have both input and correct outputs (targets), what we need to do is just assign some values to weights(here we omit the bias). Like:\n\\[ _1W=\\begin{bmatrix}1.0\\\\-0.8\\end{bmatrix}\\tag{6} \\]\nCalculating output The output is easy to be calculated: \\[ a=f(_1W^T\\mathbf{p}_1)\\tag{7} \\]\nwhen \\(\\mathbf{p}_1=\\begin{bmatrix}1\\\\ 2\\end{bmatrix}\\), we have:\n\\[ n=\\begin{bmatrix}1.0 \u0026-0.8\\end{bmatrix}\\begin{bmatrix}1\\\\2\\end{bmatrix}=-0.6\\\\ a=f(-0.6)=0\\tag{8} \\]\nhowever, the target is \\(1\\) so this is a wrong prediction of the current model. What we would do is modify the model.\nAs we mentioned above, \\(_1W\\) points to the purple region\nwhere the output is \\(1\\). So we should modify the direction of \\(_1W\\) close to the direction of \\(p_1\\).\nThe intuitive strategy is setting \\(_1W=p_i\\) when the output is \\(0\\) while the target is \\(1\\) and setting \\(_1W=-p_i\\) when the output is \\(1\\) while the target is \\(0\\)(where \\(i\\) less than the size of the training set). However, there are only three training points in this example, so there are only three possible decision boundaries, it can not guarantee that there must be a line \\(_1W=p_i\\) that separates the input data correctly.\nAlthough this strategy does not work, it has a good inspiration: 1. if \\(t=1\\) and \\(a=0\\), modify \\(_1W\\) close to \\(p_i\\) 2. if \\(t=0\\) and \\(a=1\\), modify \\(_1W\\) away from \\(p_i\\) or modify \\(_1W\\) close to \\(-p_i\\) equally 3. if \\(t=a\\) do nothing\nThen we find that the summation of two vectors is closer to each of the two vectors. Then our algorithm becomes:\nif \\(t=1\\) and \\(a=0\\), \\(_1W^{\\text{new}}= _1W^{\\text{old}}+p_i\\) if \\(t=0\\) and \\(a=1\\), \\(_1W^{\\text{new}}= _1W^{\\text{old}}-p_i\\) if \\(t=a\\) do nothing  Unified Learning Rule The target and output product information together to modify the model. Here we introduce the most simple but useful information - ‘error’:\n\\[ e_i=t_i-a_i\\tag{9} \\]\nso, our algorithm is\nif \\(t=1\\) and \\(a=0\\) where \\(e=1-0=1\\): \\(_1W^{\\text{new}}= _1W^{\\text{old}}+p_i\\) if \\(t=0\\) and \\(a=1\\) where \\(e=0-1=-1\\): \\(_1W^{\\text{new}}= _1W^{\\text{old}}-p_i\\) if \\(t=a\\) where \\(e=t-a=0\\): do nothing  and it’s not hard to notice that \\(e\\) has the same sign with \\(p_i\\). Then the algorithm can be simplified as:\n\\[ _1W^{\\text{new}}=_1W^{\\text{old}}+e\\cdot p_i=_1W^{\\text{old}}+(t_i-a_i)\\cdot p_i\\tag{10} \\]\nThis can be easily extended to bias:\n\\[ b^{\\text{new}}=b^{\\text{old}}+e\\cdot 1=b^{\\text{old}}+(t_i-a_i)\\tag{11} \\]\nand to the multiple neurons perceptron networks, the algorithm in matrix form is:\n\\[ W^{\\text{new}}=W^{\\text{old}}+\\mathbf{e}\\cdot \\mathbf{p_i}\\\\ \\mathbf{b}^{\\text{new}}=\\mathbf{b}^{\\text{old}}+\\mathbf{e}_i\\cdot \\mathbf{1}\\tag{12} \\]\nConclusion Perceptron is still working today The learning rule of the perceptron is a good example of having a close look at the learning rules of neuron networks Perceptron has some connection with other machine learning algorithms like linear classification A single perceptron has a lot of limits but multiple layers of perceptrons are more powerful  References  Demuth, H.B., Beale, M.H., De Jess, O. and Hagan, M.T., 2014. Neural network design. Martin Hagan.↩︎\n   ","wordCount":"1253","inLanguage":"en","datePublished":"2019-12-11T21:30:42Z","dateModified":"2022-05-03T10:39:43+08:00","author":{"@type":"Person","name":"Anthony Tan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://anthony-tan.com/Learning-Rules-and-Perceptron-Learning-Rule/"},"publisher":{"@type":"Organization","name":"Anthony's Blogs","logo":{"@type":"ImageObject","url":"https://anthony-tan.com/logo.png"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://anthony-tan.com accesskey=h title="Anthony's Blogs (Alt + H)">Anthony's Blogs</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://anthony-tan.com/machine_learning/ title="Machine Learning"><span>Machine Learning</span></a></li><li><a href=https://anthony-tan.com/deep_learning/ title="Deep Learning"><span>Deep Learning</span></a></li><li><a href=https://anthony-tan.com/reinforcement_learning/ title="Reinforcement Learning"><span>Reinforcement Learning</span></a></li><li><a href=https://anthony-tan.com/math/ title=Math><span>Math</span></a></li><li><a href=https://anthony-tan.com/others/ title=Others><span>Others</span></a></li><li><a href=https://anthony-tan.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://anthony-tan.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://anthony-tan.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://anthony-tan.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://anthony-tan.com>Home</a>&nbsp;»&nbsp;<a href=https://anthony-tan.com/deep_learning/>Deep Learning</a></div><h1 class=post-title>Learning Rules and Perceptron Learning Rule</h1><div class=post-meta><span title="2019-12-11 21:30:42 +0000 UTC">December 11, 2019</span>&nbsp;·&nbsp;<span title="2022-05-03 10:39:43 +0800 +0800">(Last Modification: May 3, 2022)</span>&nbsp;·&nbsp;Anthony Tan</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#preliminaries aria-label=Preliminaries>Preliminaries</a></li><li><a href=#learning-rules1 aria-label="Learning Rules1">Learning Rules<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a></a></li><li><a href=#perceptron-architecture aria-label="Perceptron Architecture">Perceptron Architecture</a><ul><li><a href=#single-neuron-perceptron aria-label="Single-Neuron Perceptron">Single-Neuron Perceptron</a></li><li><a href=#multiple-neuron-perceptron aria-label="Multiple-Neuron Perceptron">Multiple-Neuron Perceptron</a></li></ul></li><li><a href=#perceptron-learning-rule aria-label="Perceptron Learning Rule">Perceptron Learning Rule</a><ul><li><a href=#constructing-learning-rules aria-label="Constructing Learning Rules">Constructing Learning Rules</a><ul><li><a href=#assigning-some-initial-values aria-label="Assigning Some Initial Values">Assigning Some Initial Values</a></li><li><a href=#calculating-output aria-label="Calculating output">Calculating output</a></li></ul></li><li><a href=#unified-learning-rule aria-label="Unified Learning Rule">Unified Learning Rule</a></li></ul></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h2 id=preliminaries>Preliminaries<a hidden class=anchor aria-hidden=true href=#preliminaries>#</a></h2><ol type=1><li><a href=#TODO>supervised learning</a></li><li><a href=#TODO>unsupervised learning</a></li><li><a href=#TODO>reinforcement learning</a></li><li><a href=https://anthony-tan.com/An-Introduction-to-Neural-Networks/>‘An Introduction to Neural Networks’</a></li></ol><h2 id=learning-rules1>Learning Rules<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a><a hidden class=anchor aria-hidden=true href=#learning-rules1>#</a></h2><p>We have built some neural network models in the post <a href=https://anthony-tan.com/An-Introduction-to-Neural-Networks/>‘An Introduction to Neural Networks’</a> and as we know architectures and learning rules are two main aspects of designing a useful network. The architectures we have introduced could not be used yet. What we are going to do is to investigate the learning rules for different architectures.</p><p><strong>The learning rule is a procedure to modify weights, bias, and other parameters in the model to perform a certain task.</strong> There are generally 3 types of learning rules:</p><ol type=1><li>Supervised Learning</li></ol><ul><li>There is a training set of the model that contains a number of input data as well as correct output values that are also known as targets, like the set <span class="math inline">\(\{\mathbf{p}_1,t_1\},\{\mathbf{p}_2,t_2\},\cdots,\{\mathbf{p}_Q,t_Q\},\)</span> where <span class="math inline">\(\mathbf{p}_i\)</span> (for <span class="math inline">\(i&lt;Q\)</span>) is the input of the model and <span class="math inline">\(t_i\)</span>(for <span class="math inline">\(i&lt;Q\)</span>) is the corresponding target(any kind of output, like labels, regression values)</li><li>the whole process is: <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_05_supervised_learning.jpeg></li><li>where target and current output are used to modify the neuron network to produce an output as close to the target as possible according to the input.</li></ul><ol start=2 type=1><li>Unsupervised Learning</li></ol><ul><li>Unlike supervised learning, unsupervised learning doesn’t know the correct output at all, in other words, what the neuron network knows is only the inputs, and how to modify the parameters in the model is depend only on the inputs. This kind of learning is always used to perform clustering operations or vector quantization. <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_05_unsupervised_learning.jpeg></li></ul><ol start=3 type=1><li>Reinforcement learning</li></ol><ul><li>it is another learning rule which is more like supervised learning and works more like a biological brain.</li><li>there is no correct target as well but there is a grade to measure the performance of the network over some sequence of input. <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_06_reinforcement_learning.jpeg></li></ul><h2 id=perceptron-architecture>Perceptron Architecture<a hidden class=anchor aria-hidden=true href=#perceptron-architecture>#</a></h2><p>A perceptron is an easy model of a neuron, and what we are interested in is how to design a learning rule or develop a certain algorithm to make a perceptron possible to classify input signals. Perceptron is the easiest neuron model, and it is a good basis for more complex networks.</p><p>In a perceptron, it has weights, biases, and transfer functions. These are basic components of a neuron model. However, the transfer function here is specialized as a <a href=https://anthony-tan.com/Neuron-Model-and-Network-Architecture/>‘hard limit function’</a></p><p><span class="math display">\[
f(x) = \begin{cases}
0& \text{ if } x&lt;0\\
1& \text{ if } x\geq 0
\end{cases}\tag{1}
\]</span></p><p>and abbreviated notation with a layer of <span class="math inline">\(S\)</span> neuron network is:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_06_perceptron.jpeg></p><p>where <span class="math inline">\(W\)</span> are the weight matrix of <span class="math inline">\(S\)</span> perceptrons. And each row of the matrix contains all the weight of a perceptron.</p><h3 id=single-neuron-perceptron>Single-Neuron Perceptron<a hidden class=anchor aria-hidden=true href=#single-neuron-perceptron>#</a></h3><p>In some simple models, we can visualize a line or a plane named <a href=https://anthony-tan.com/Discriminant-Functions-and-Decision-Boundary/>‘decision boundary’</a> which is determined by the input vectors who make the input of its transfer function <span class="math inline">\(n=0\)</span>. For instance, in a 2-dimensional linear classification task, we were asked to find a line that can separate the input points into two different classes. This line here acts as a decision boundary and all the points on the line would produce <span class="math inline">\(0\)</span> output through the linear model.</p><p>Let’s start to study with one perceptron.</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_11_2_input_perceptron.jpeg></p><p>Its decision boundary is the line:</p><p><span class="math display">\[
n=w_{1,1}p_1+w_{1,2}p_2+b=0\tag{2}
\]</span></p><p>For example, when <span class="math inline">\(w_{1,1}=1\)</span>, <span class="math inline">\(w_{1,2}=1\)</span> and <span class="math inline">\(b=-1\)</span>, we get the decision boundary:</p><p><span class="math display">\[
p_1+p_2-1=0\tag{3}
\]</span></p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_10_decision_boundary.png></p><p>from the figure, we can conclude the weight vector has the following properties:</p><ol type=1><li><span class="math inline">\(W\)</span> always points to the purple region where <span class="math inline">\(n=w_{1,1}p_1+w_{1,2}p_2+b>0\)</span></li><li>The relation of <span class="math inline">\(W\)</span> and the direction of the decision boundary is orthogonality.</li></ol><p>Can this simple example perform some task? Of course. If we test the input <span class="math inline">\(\mathbf{p}_1=\begin{bmatrix}0&0\end{bmatrix}^T,\mathbf{p}_1=\begin{bmatrix}0&1\end{bmatrix}^T,\mathbf{p}_1=\begin{bmatrix}1&0\end{bmatrix}^T,\mathbf{p}_1=\begin{bmatrix}1&1\end{bmatrix}^T\)</span> respectively, we could get <span class="math inline">\(a_1=0,a_2=0,a_3=0,a_4=1\)</span>. This is the ‘and’ operation in logical calculation.</p><table><thead><tr class=header><th style=text-align:center></th><th style=text-align:center>input</th><th style=text-align:center>output</th></tr></thead><tbody><tr class=odd><td style=text-align:center></td><td style=text-align:center><span class="math inline">\(\begin{bmatrix}0&0\end{bmatrix}^T\)</span></td><td style=text-align:center><span class="math inline">\(0\)</span></td></tr><tr class=even><td style=text-align:center></td><td style=text-align:center><span class="math inline">\(\begin{bmatrix}0&1\end{bmatrix}^T\)</span></td><td style=text-align:center><span class="math inline">\(0\)</span></td></tr><tr class=odd><td style=text-align:center></td><td style=text-align:center><span class="math inline">\(\begin{bmatrix}1&0\end{bmatrix}^T\)</span></td><td style=text-align:center><span class="math inline">\(0\)</span></td></tr><tr class=even><td style=text-align:center></td><td style=text-align:center><span class="math inline">\(\begin{bmatrix}1&1\end{bmatrix}^T\)</span></td><td style=text-align:center><span class="math inline">\(1\)</span></td></tr></tbody></table><h3 id=multiple-neuron-perceptron>Multiple-Neuron Perceptron<a hidden class=anchor aria-hidden=true href=#multiple-neuron-perceptron>#</a></h3><p>A multiple neuron perceptron is just a combination of some perceptrons, whose weight matrix <span class="math inline">\(W\)</span> has multiple rows. And the transpose of row <span class="math inline">\(i\)</span> of the <span class="math inline">\(W\)</span> is notated as <span class="math inline">\(_iW\)</span>(column form of the <span class="math inline">\(i\)</span>th row in <span class="math inline">\(W\)</span>) then the <span class="math inline">\(i\)</span> th neuron has the decision boundary:</p><p><span class="math display">\[
_iW^T\mathbf{p}+b_i=0\tag{4}
\]</span></p><p>For the property of <a href=TODO>hard limit function</a> that the output could just be one of <span class="math inline">\(\{0,1\}\)</span>. And for <span class="math inline">\(S\)</span> neurons, there are at most <span class="math inline">\(2^S\)</span> categories, that is to say to a <span class="math inline">\(S\)</span> neuron perceptron in one layer it is impossible to solve the problems containing more than <span class="math inline">\(2^S\)</span> classes.</p><h2 id=perceptron-learning-rule>Perceptron Learning Rule<a hidden class=anchor aria-hidden=true href=#perceptron-learning-rule>#</a></h2><p>Perceptron learning rule here is a kind of supervised learning rule. Recall some results above: 1. supervised learning had both input and corresponding correct target. 2. target, the output produced by the current model, and input produced the information on how to modify the model 3. <span class="math inline">\(W\)</span> always points to the region where the output is <span class="math inline">\(a=1\)</span></p><h3 id=constructing-learning-rules>Constructing Learning Rules<a hidden class=anchor aria-hidden=true href=#constructing-learning-rules>#</a></h3><p>With the above results we try to design the rule and assume training dates are:</p><p><span class="math display">\[
\{\begin{bmatrix}1\\2\end{bmatrix},1\},\{\begin{bmatrix}-1\\2\end{bmatrix},0\},\{\begin{bmatrix}0\\-1\end{bmatrix},0\}\tag{5}
\]</span></p><h4 id=assigning-some-initial-values>Assigning Some Initial Values<a hidden class=anchor aria-hidden=true href=#assigning-some-initial-values>#</a></h4><p>To modify the model, we need the output which is produced by the weights and input. And for this supervised learning algorithm we have both input and correct outputs (targets), what we need to do is just assign some values to weights(here we omit the bias). Like:</p><p><span class="math display">\[
_1W=\begin{bmatrix}1.0\\-0.8\end{bmatrix}\tag{6}
\]</span></p><h4 id=calculating-output>Calculating output<a hidden class=anchor aria-hidden=true href=#calculating-output>#</a></h4><p>The output is easy to be calculated: <span class="math display">\[
a=f(_1W^T\mathbf{p}_1)\tag{7}
\]</span></p><p>when <span class="math inline">\(\mathbf{p}_1=\begin{bmatrix}1\\ 2\end{bmatrix}\)</span>, we have:</p><p><span class="math display">\[
n=\begin{bmatrix}1.0 &-0.8\end{bmatrix}\begin{bmatrix}1\\2\end{bmatrix}=-0.6\\
a=f(-0.6)=0\tag{8}
\]</span></p><p>however, the target is <span class="math inline">\(1\)</span> so this is a wrong prediction of the current model. What we would do is modify the model.</p><p>As we mentioned above, <span class="math inline">\(_1W\)</span> points to the purple region</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_04_30_20_10_decision_boundary.png></p><p>where the output is <span class="math inline">\(1\)</span>. So we should modify the direction of <span class="math inline">\(_1W\)</span> close to the direction of <span class="math inline">\(p_1\)</span>.</p><p>The intuitive strategy is setting <span class="math inline">\(_1W=p_i\)</span> when the output is <span class="math inline">\(0\)</span> while the target is <span class="math inline">\(1\)</span> and setting <span class="math inline">\(_1W=-p_i\)</span> when the output is <span class="math inline">\(1\)</span> while the target is <span class="math inline">\(0\)</span>(where <span class="math inline">\(i\)</span> less than the size of the training set). However, there are only three training points in this example, so there are only three possible decision boundaries, it can not guarantee that there must be a line <span class="math inline">\(_1W=p_i\)</span> that separates the input data correctly.</p><p>Although this strategy does not work, it has a good inspiration: 1. if <span class="math inline">\(t=1\)</span> and <span class="math inline">\(a=0\)</span>, modify <span class="math inline">\(_1W\)</span> close to <span class="math inline">\(p_i\)</span> 2. if <span class="math inline">\(t=0\)</span> and <span class="math inline">\(a=1\)</span>, modify <span class="math inline">\(_1W\)</span> away from <span class="math inline">\(p_i\)</span> or modify <span class="math inline">\(_1W\)</span> close to <span class="math inline">\(-p_i\)</span> equally 3. if <span class="math inline">\(t=a\)</span> do nothing</p><p>Then we find that the summation of two vectors is closer to each of the two vectors. Then our algorithm becomes:</p><ol type=1><li>if <span class="math inline">\(t=1\)</span> and <span class="math inline">\(a=0\)</span>, <span class="math inline">\(_1W^{\text{new}}= _1W^{\text{old}}+p_i\)</span></li><li>if <span class="math inline">\(t=0\)</span> and <span class="math inline">\(a=1\)</span>, <span class="math inline">\(_1W^{\text{new}}= _1W^{\text{old}}-p_i\)</span></li><li>if <span class="math inline">\(t=a\)</span> do nothing</li></ol><h3 id=unified-learning-rule>Unified Learning Rule<a hidden class=anchor aria-hidden=true href=#unified-learning-rule>#</a></h3><p>The target and output product information together to modify the model. Here we introduce the most simple but useful information - ‘error’:</p><p><span class="math display">\[
e_i=t_i-a_i\tag{9}
\]</span></p><p>so, our algorithm is</p><ol type=1><li>if <span class="math inline">\(t=1\)</span> and <span class="math inline">\(a=0\)</span> where <span class="math inline">\(e=1-0=1\)</span>: <span class="math inline">\(_1W^{\text{new}}= _1W^{\text{old}}+p_i\)</span></li><li>if <span class="math inline">\(t=0\)</span> and <span class="math inline">\(a=1\)</span> where <span class="math inline">\(e=0-1=-1\)</span>: <span class="math inline">\(_1W^{\text{new}}= _1W^{\text{old}}-p_i\)</span></li><li>if <span class="math inline">\(t=a\)</span> where <span class="math inline">\(e=t-a=0\)</span>: do nothing</li></ol><p>and it’s not hard to notice that <span class="math inline">\(e\)</span> has the same sign with <span class="math inline">\(p_i\)</span>. Then the algorithm can be simplified as:</p><p><span class="math display">\[
_1W^{\text{new}}=_1W^{\text{old}}+e\cdot p_i=_1W^{\text{old}}+(t_i-a_i)\cdot p_i\tag{10}
\]</span></p><p>This can be easily extended to bias:</p><p><span class="math display">\[
b^{\text{new}}=b^{\text{old}}+e\cdot 1=b^{\text{old}}+(t_i-a_i)\tag{11}
\]</span></p><p>and to the multiple neurons perceptron networks, the algorithm in matrix form is:</p><p><span class="math display">\[
W^{\text{new}}=W^{\text{old}}+\mathbf{e}\cdot \mathbf{p_i}\\
\mathbf{b}^{\text{new}}=\mathbf{b}^{\text{old}}+\mathbf{e}_i\cdot \mathbf{1}\tag{12}
\]</span></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><ol type=1><li>Perceptron is still working today</li><li>The learning rule of the perceptron is a good example of having a close look at the learning rules of neuron networks</li><li>Perceptron has some connection with other machine learning algorithms like linear classification</li><li>A single perceptron has a lot of limits but multiple layers of perceptrons are more powerful</li></ol><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p>Demuth, H.B., Beale, M.H., De Jess, O. and Hagan, M.T., 2014. Neural network design. Martin Hagan.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://anthony-tan.com/tags/artificial-neural-networks/>Artificial Neural Networks</a></li><li><a href=https://anthony-tan.com/tags/artificial-intelligence/>Artificial Intelligence</a></li><li><a href=https://anthony-tan.com/tags/perceptron-learning-rule/>Perceptron Learning Rule</a></li><li><a href=https://anthony-tan.com/tags/learning-rules/>Learning Rules</a></li><li><a href=https://anthony-tan.com/tags/multiple-neuron-perceptron/>Multiple-Neuron Perceptron</a></li><li><a href=https://anthony-tan.com/tags/perceptron-architecture/>Perceptron Architecture</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Learning Rules and Perceptron Learning Rule on twitter" href="https://twitter.com/intent/tweet/?text=Learning%20Rules%20and%20Perceptron%20Learning%20Rule&url=https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f&hashtags=ArtificialNeuralNetworks%2cArtificialIntelligence%2cperceptronlearningrule%2cLearningRules%2cMultiple-NeuronPerceptron%2cPerceptronArchitecture"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learning Rules and Perceptron Learning Rule on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f&title=Learning%20Rules%20and%20Perceptron%20Learning%20Rule&summary=Learning%20Rules%20and%20Perceptron%20Learning%20Rule&source=https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learning Rules and Perceptron Learning Rule on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f&title=Learning%20Rules%20and%20Perceptron%20Learning%20Rule"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learning Rules and Perceptron Learning Rule on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learning Rules and Perceptron Learning Rule on whatsapp" href="https://api.whatsapp.com/send?text=Learning%20Rules%20and%20Perceptron%20Learning%20Rule%20-%20https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Learning Rules and Perceptron Learning Rule on telegram" href="https://telegram.me/share/url?text=Learning%20Rules%20and%20Perceptron%20Learning%20Rule&url=https%3a%2f%2fanthony-tan.com%2fLearning-Rules-and-Perceptron-Learning-Rule%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><figure class=article-discussion><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//anthony-tan-com.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></figure></article></main><footer class=footer><span>&copy; 2022 <a href=https://anthony-tan.com>Anthony's Blogs</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script><script src=https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.1.4/mermaid.min.js crossorigin=anonymous></script>
<script>mermaid.init(void 0,".language-mermaid")</script></body></html>
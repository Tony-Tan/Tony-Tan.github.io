<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Steepest Descent Method | Anthony's Blogs</title><meta name=keywords content="Artificial Neural Networks,Artificial Intelligence,Steepest Descent,optimization"><meta name=description content="Preliminaries ‘An Introduction to Performance Optimization’ Linear algebra Calculus 1,2  Direction Based Algorithm and a Variation1 This post describes a direction searching algorithm(\(\mathbf{x}_{k}\)). And its variation gives a way to estimate step length (\(\alpha_k\)).
Steepest Descent To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill."><meta name=author content="Anthony Tan"><link rel=canonical href=https://anthony-tan.com/Steepest-Descent-Method/><link crossorigin=anonymous href=../assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://anthony-tan.com/logo.png><link rel=apple-touch-icon href=https://anthony-tan.com/logo.png><link rel=mask-icon href=https://anthony-tan.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-12","auto"),ga("send","pageview"))</script><meta property="og:title" content="Steepest Descent Method"><meta property="og:description" content="Preliminaries ‘An Introduction to Performance Optimization’ Linear algebra Calculus 1,2  Direction Based Algorithm and a Variation1 This post describes a direction searching algorithm(\(\mathbf{x}_{k}\)). And its variation gives a way to estimate step length (\(\alpha_k\)).
Steepest Descent To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill."><meta property="og:type" content="article"><meta property="og:url" content="https://anthony-tan.com/Steepest-Descent-Method/"><meta property="article:section" content="deep_learning"><meta property="article:published_time" content="2019-12-20T11:39:19+00:00"><meta property="article:modified_time" content="2022-05-02T18:43:13+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Steepest Descent Method"><meta name=twitter:description content="Preliminaries ‘An Introduction to Performance Optimization’ Linear algebra Calculus 1,2  Direction Based Algorithm and a Variation1 This post describes a direction searching algorithm(\(\mathbf{x}_{k}\)). And its variation gives a way to estimate step length (\(\alpha_k\)).
Steepest Descent To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Deep Learning","item":"https://anthony-tan.com/deep_learning/"},{"@type":"ListItem","position":3,"name":"Steepest Descent Method","item":"https://anthony-tan.com/Steepest-Descent-Method/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Steepest Descent Method","name":"Steepest Descent Method","description":"Preliminaries ‘An Introduction to Performance Optimization’ Linear algebra Calculus 1,2  Direction Based Algorithm and a Variation1 This post describes a direction searching algorithm(\\(\\mathbf{x}_{k}\\)). And its variation gives a way to estimate step length (\\(\\alpha_k\\)).\nSteepest Descent To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill.","keywords":["Artificial Neural Networks","Artificial Intelligence","Steepest Descent","optimization"],"articleBody":"Preliminaries ‘An Introduction to Performance Optimization’ Linear algebra Calculus 1,2  Direction Based Algorithm and a Variation1 This post describes a direction searching algorithm(\\(\\mathbf{x}_{k}\\)). And its variation gives a way to estimate step length (\\(\\alpha_k\\)).\nSteepest Descent To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill. And the crucial of this algorithm is that every iteration makes the performance index decrease:\n\\[ F(\\mathbf{x}_{k+1})Our mission is to find the direction \\(\\mathbf{p}_k\\) with a relatively short step length \\(\\alpha_k\\) which leads us downhill.\nThe first-order Taylor series of an iterative step is:\n\\[ F(\\mathbf{x}_{k+1})=F(\\mathbf{x}_{k}+\\Delta \\mathbf{x}_k)\\approx F(\\mathbf{x}_{k})+\\mathbf{g}^T\\Delta\\mathbf{x}_k\\tag{2} \\]\nwhere \\(\\mathbf{g}_k\\) is the gradient at position \\(\\mathbf{x}\\) of the performance index \\(F(\\mathbf{x})\\) which means:\n\\[ \\mathbf{g}_k = \\nabla F(\\mathbf{x})\\bigg |_{\\mathbf{x}=\\mathbf{x}_k}\\tag{3} \\]\nFrom equation(1) and equation(2) for the purpose \\(F(\\mathbf{x}_{k+1}), we need:\n\\[ \\mathbf{g}^T\\Delta\\mathbf{x}_k( \\(\\Delta\\mathbf{x}_k\\) , the change of \\(\\mathbf{x}_k\\), can also be represented by step length \\(\\alpha_k\\) and direction \\(\\mathbf{p}\\), then the equation(4) has a equivalent form:\n\\[ \\alpha_k\\mathbf{g}^T\\Delta\\mathbf{p}_kIn the previous posts, we have seen how to find the greatest value of \\(\\mathbf{g}^T\\Delta\\mathbf{p}_k\\). And now we can find the smallest value of \\(\\mathbf{g}^T\\Delta\\mathbf{p}_k\\) in the same way. Then we got the smallest value is:\n\\[ -\\mathbf{g}^T\\mathbf{g}\\tag{6} \\]\nwhich means that the deepest direction we would search is:\n\\[ \\Delta\\mathbf{p}_k=-\\mathbf{g}\\tag{7} \\]\nAccording to the iterative optimization algorithm framework in‘An Introduction to Performance Optimization’, the second step is :\n\\[ \\mathbf{x}_{k+1}=\\mathbf{x}_{k}-\\alpha_k\\mathbf{g}_k\\tag{8} \\]\nThe step length is also called the learning rate. And the choice of \\(\\alpha_k\\) can be:\nMinimizing \\(F(\\mathbf{x})\\) with \\(\\alpha_k\\) by minimizing along the line: \\(\\mathbf{x}_k-\\alpha_k\\mathbf{g}_k\\) Fixed \\(\\alpha_k\\), such as \\(\\alpha_k=0.002\\) Predetermined, like \\(\\alpha_k=\\frac{1}{k}\\)  An Example \\[ F(\\mathbf{x})=x_1^2+25x_2^2\\tag{9} \\]\nstart at point \\(x=\\begin{bmatrix}0.5\\\\0.5\\end{bmatrix}\\) gradient of \\(F(\\mathbf{x})\\) is \\(\\nabla F(\\mathbf{x})=\\begin{bmatrix}\\frac{\\partial F}{\\partial x_1}\\\\\\frac{\\partial F}{\\partial x_2}\\end{bmatrix}=\\begin{bmatrix}2x_1\\\\50x_2\\end{bmatrix}\\) \\(\\mathbf{g}_0=\\nabla F(\\mathbf{x})\\bigg|_{\\mathbf{x}=\\mathbf{x}_0}=\\begin{bmatrix}1\\\\25\\end{bmatrix}\\) set \\(\\alpha = 0.01\\) update: \\(\\mathbf{x}_1=\\mathbf{x}_0-0.01\\mathbf{g}_0=\\begin{bmatrix}0.5\\\\0.5\\end{bmatrix}-0.01\\begin{bmatrix}1\\\\25\\end{bmatrix}=\\begin{bmatrix}0.49\\\\0.25\\end{bmatrix}\\) update: \\(\\mathbf{x}_2=\\mathbf{x}_1-0.01\\mathbf{g}_1=\\begin{bmatrix}0.49\\\\0.25\\end{bmatrix}-0.01\\begin{bmatrix}0.98\\\\12.5\\end{bmatrix}=\\begin{bmatrix}0.4802\\\\0.125\\end{bmatrix}\\) go on updating until the smallest point is achieved.  The whole trajectory looks like this:\nand the learning rate, step length is a constant in this algorithm, however, we can test 2 different values and watch their behavior. When we set \\(\\alpha=0.01\\), we have:\nand when we set \\(\\alpha=0.02\\), we have: These results illustrated:\nIn first several steps, the descent speed is faster than in later steps A greater learning rate seems to have a higher speed This algorithm can converge to the minimum point.  The second point gives us a new idea, of what will the algorithms do when we have a relatively bigger learning rate. To be on the safe side we select a not so big learning rate \\(\\alpha=0.05\\), we have:\nthis algorithm diverges, which means it would never stop at the minimum and get farther and farther as steps go on. So we have to take care of the value of the learning rate, a small learning rate can slow down the algorithm but a big one can break up the algorithm.\nStable Learning Rates To have a fast speed and converge to the minimum, we need to study the learning rate \\(\\alpha\\). To simplify the problem, we start with supposing the performance index is a quadratic function:\n\\[ F(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^TA\\mathbf{x}+\\mathbf{d}^T\\mathbf{x}+c\\tag{10} \\]\nand we have already known its gradient is:\n\\[ \\nabla F(\\mathbf{x})=A \\mathbf{x}+\\mathbf{d}\\tag{11} \\]\nwe take equation(11) into update step equation(8), we have:\n\\[ \\mathbf{x}_{k+1}=\\mathbf{x}_k-\\alpha\\mathbf{g}_k=\\mathbf{x}_k-\\alpha(A \\mathbf{x}_k+\\mathbf{d})\\tag{12} \\]\nor an equivalent form:\n\\[ \\mathbf{x}_{k+1}=(I-\\alpha A)\\mathbf{x}_k - \\alpha\\mathbf{d}\\tag{13} \\]\nIn the linear algebra course or other courses, this equation is called a ‘linear dynamic system’. To make the system stable, the eigenvalues of \\(I-\\alpha A\\) are less than one in magnitude. And \\(I-\\alpha A\\) has the same eigenvectors with \\(A\\). Let \\([\\lambda_1,\\lambda_2,\\cdots,\\lambda_n]\\) be the eigenvalues of \\(A\\) and let \\([\\mathbf{z}_1,\\mathbf{z}_2,\\cdots,\\mathbf{z}_n]\\) be the eigenvectors of \\(A\\)\n\\[ [I-\\alpha A]\\mathbf{z}_i=\\mathbf{z}_i-\\alpha A\\mathbf{z}_i=\\mathbf{z}_i-\\alpha \\lambda_i\\mathbf{z}_i=(1-\\alpha\\lambda_i)\\mathbf{z}_i\\tag{14} \\]\n\\(I-\\alpha A\\) has the same eigenvectors with \\(A\\) and has the eigenvalues: \\([1-\\alpha\\lambda_1,1-\\alpha\\lambda_2,\\cdots,1-\\alpha\\lambda_n]\\)\nConcerning the equation(13) and eigenvalues of \\(I-\\alpha A\\) to stabilize the system which here is the steepest descent algorithm, we need:\n\\[ \\begin{aligned} \u0026|1-\\alpha \\lambda_i|\u0026for \\(\\alpha0\\)\n\\[ \\begin{aligned} \\frac{2}{\\alpha}\u0026 \\lambda_i\u00260\\\\ \\end{aligned}\\tag{16} \\]\nfrom equation(16), we finally have \\[ \\frac{2}{\\lambda_i}\\alpha\\tag{17} \\]\nwhich implies:\n\\[ \\frac{2}{\\lambda_{\\text{max}}}\\alpha\\tag{18} \\]\nThis gives us the maximum stable learning rate is inversely proportional to the maximum curvature(direction along with eigenvector according to the maximum eigenvalue \\(\\lambda_\\text{max}\\)) of the quadratic function.\nLet’s go back to the example, the Hessian matrix of the equation(9) is: \\[ A=\\begin{bmatrix} 2\u00260\\\\0\u002650 \\end{bmatrix}\\tag{19} \\]\nits eigenvectors and eigenvalues are: \\[ \\{\\lambda_1=2,\\mathbf{z}_1=\\begin{bmatrix}1\\\\0\\end{bmatrix}\\},\\{\\lambda_2=50,\\mathbf{z}_2=\\begin{bmatrix}0\\\\1\\end{bmatrix}\\}\\tag{20} \\]\ntaking \\(\\lambda_\\text{max}=\\lambda_2=50\\) into equation(18), we get: \\[ \\alpha_\\text{max}so, let’s check the behavior of the algorithm when \\(\\alpha=0.039\\) and \\(\\alpha=0.041\\):\nset \\(\\alpha=0.039\\) we have: set \\(\\alpha=0.041\\) we have:  Up to now, both concepts and implements have been built to prove the correctness of the algorithm. And we also have the following tips:\nThe algorithm tends to converge most quickly in the direction of the eigenvector corresponding to the largest eigenvalue The algorithm tends to converge most slowly in the direction of the eigenvector corresponding to the smallest eigenvalue Do not overshoot the minimum point for the too-long step(learning rate \\(\\alpha\\))  Minimizing along a Line The section above gives us the upper bound of \\(\\alpha\\), but we have three kinds of strategies for selecting a \\(\\alpha\\).\nThe first one is “Minimizing \\(F(\\mathbf{x})\\) with \\(\\alpha_k\\) by minimizing along the line: \\(\\mathbf{x}_k-\\alpha_k\\mathbf{g}_k\\)”. What shall we do with this kind of \\(\\alpha\\)?\nTo arbitrary functions, the stationary point along a direction can be calculated by:\n\\[ \\begin{aligned} \u0026\\frac{dF}{d\\alpha_k}(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k)\\\\ \u0026=\\nabla F(\\mathbf{x})^T\\bigg|_{\\mathbf{x}=\\mathbf{x}_k}\\mathbf{p}_k+\\alpha_k\\mathbf{p}_k^T\\nabla F^2(\\mathbf{x})^T\\bigg|_{\\mathbf{x}=\\mathbf{x}_k}\\mathbf{p}_k\\\\ \u0026=0 \\end{aligned}\\tag{22} \\]\nand then\n\\[ \\alpha=-\\frac{\\nabla F(\\mathbf{x})^T\\bigg|_{\\mathbf{x}=\\mathbf{x}_k}\\mathbf{p}_k}{\\mathbf{p}_k^T\\nabla F^2(\\mathbf{x})\\bigg|_{\\mathbf{x}=\\mathbf{x}_k}\\mathbf{p}_k}=-\\frac{\\mathbf{g}^T_k\\mathbf{p}_k}{\\mathbf{p}_k^TA_k\\mathbf{p}_k}\\tag{23} \\]\nwhere: \\(A_k\\) is the Hessian matrix of an old guess \\(\\mathbf{x}_k\\):\n\\[ A_k=\\nabla^2F(\\mathbf{x})\\bigg|_{\\mathbf{x}=\\mathbf{x}_k}\\tag{24} \\]\nHere we look at an example:\n\\[ F(x)=\\frac{1}{2}\\mathbf{x}^T\\begin{bmatrix} 2\u00261\\\\1\u00262 \\end{bmatrix}\\mathbf{x}\\tag{25} \\]\nwith the initial guess \\[ \\mathbf{x}_0=\\begin{bmatrix}0.8\\\\-0.25\\end{bmatrix}\\tag{26} \\]\nthe gradient of the function is\n\\[ \\nabla F(\\mathbf{x})=\\begin{bmatrix}2x_1+x_2\\\\x_1+2x_2\\end{bmatrix}\\tag{27} \\]\nthe initial direction of the algorithm is\n\\[ \\mathbf{p}_0=-\\mathbf{g}_0=-\\nabla F(\\mathbf{x})\\bigg|_{\\mathbf{x}=\\mathbf{x}_k}=\\begin{bmatrix}-1.35\\\\-0.3\\end{bmatrix}\\tag{28} \\]\nand take equation(28) and \\(A=\\begin{bmatrix}2\u00261\\\\1\u00262\\end{bmatrix}\\) into equation(23): \\[ \\alpha_0=\\frac{\\begin{bmatrix}1.35\u00260.3\\end{bmatrix}\\begin{bmatrix}2\u00261\\\\1\u00262\\end{bmatrix}}{\\begin{bmatrix}1.35\u00260.3\\end{bmatrix}\\begin{bmatrix}2\u00261\\\\1\u00262\\end{bmatrix}\\begin{bmatrix}1.35\\\\0.3\\end{bmatrix}}=0.413\\tag{29} \\]\nand take all these data into equation(8):\n\\[ \\mathbf{x}_1=\\mathbf{x}_0-\\alpha_0\\mathbf{g}_0=\\begin{bmatrix}0.8\\\\-0.25\\end{bmatrix}-0.413\\begin{bmatrix}1.35\\\\0.3\\end{bmatrix}=\\begin{bmatrix}0.24\\\\-0.37\\end{bmatrix}\\tag{30} \\]\nWhat is going on is repeating the steps: equation(26) to equation(30) until some terminative conditions are achieved. It works like this:\nAll the new directions in the steps are orthogonal to their last direction:\n\\[ \\mathbf{p}_{k+1}^T\\mathbf{p}_k=\\mathbf{g}_{k+1}^T\\mathbf{p}_k=0\\tag{31} \\]\nwhat we need now is to proof is \\(\\mathbf{g}_{k+1}^T\\mathbf{p}_k=0\\), with the chain rule of equation(22):\n\\[ \\begin{aligned} \\frac{d}{d\\alpha_k}F(\\mathbf{x}_{k+1})\u0026=\\frac{d}{d\\alpha_k}F(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k)\\\\ \u0026=\\nabla F(\\mathbf{x})^T\\bigg|_{\\mathbf{x}=\\mathbf{x}_{k+1}}\\frac{d}{d\\alpha_k}(\\mathbf{x}_k+\\alpha_k\\mathbf{p}_k)\\\\ \u0026=\\nabla F(\\mathbf{x})^T\\bigg|_{\\mathbf{x}=\\mathbf{x}_{k+1}}\\mathbf{p}_k\\\\ \u0026=0 \\end{aligned}\\tag{32} \\]\nequation(32) gives us: a new direction is always orthogonal to the last step direction at the minimum point of the function along the last step direction. This is also an inspiration for another algorithm called conjugate direction.\nReferences  Demuth, H.B., Beale, M.H., De Jess, O. and Hagan, M.T., 2014. Neural network design. Martin Hagan.↩︎\n   ","wordCount":"1121","inLanguage":"en","datePublished":"2019-12-20T11:39:19Z","dateModified":"2022-05-02T18:43:13+08:00","author":{"@type":"Person","name":"Anthony Tan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://anthony-tan.com/Steepest-Descent-Method/"},"publisher":{"@type":"Organization","name":"Anthony's Blogs","logo":{"@type":"ImageObject","url":"https://anthony-tan.com/logo.png"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://anthony-tan.com accesskey=h title="Anthony's Blogs (Alt + H)">Anthony's Blogs</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://anthony-tan.com/machine_learning/ title="Machine Learning"><span>Machine Learning</span></a></li><li><a href=https://anthony-tan.com/deep_learning/ title="Deep Learning"><span>Deep Learning</span></a></li><li><a href=https://anthony-tan.com/reinforcement_learning/ title="Reinforcement Learning"><span>Reinforcement Learning</span></a></li><li><a href=https://anthony-tan.com/math/ title=Math><span>Math</span></a></li><li><a href=https://anthony-tan.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://anthony-tan.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://anthony-tan.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://anthony-tan.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://anthony-tan.com>Home</a>&nbsp;»&nbsp;<a href=https://anthony-tan.com/deep_learning/>Deep Learning</a></div><h1 class=post-title>Steepest Descent Method</h1><div class=post-meta><span title="2019-12-20 11:39:19 +0000 UTC">December 20, 2019</span>&nbsp;·&nbsp;<span title="2022-05-02 18:43:13 +0800 +0800">(Last Modification: May 2, 2022)</span>&nbsp;·&nbsp;Anthony Tan</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#preliminaries aria-label=Preliminaries>Preliminaries</a></li><li><a href=#direction-based-algorithm-and-a-variation1 aria-label="Direction Based Algorithm and a Variation1">Direction Based Algorithm and a Variation<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a></a></li><li><a href=#steepest-descent aria-label="Steepest Descent">Steepest Descent</a><ul><li><a href=#an-example aria-label="An Example">An Example</a></li></ul></li><li><a href=#stable-learning-rates aria-label="Stable Learning Rates">Stable Learning Rates</a></li><li><a href=#minimizing-along-a-line aria-label="Minimizing along a Line">Minimizing along a Line</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h2 id=preliminaries>Preliminaries<a hidden class=anchor aria-hidden=true href=#preliminaries>#</a></h2><ol type=1><li><a href=#TODO>‘An Introduction to Performance Optimization’</a></li><li>Linear algebra</li><li>Calculus 1,2</li></ol><h2 id=direction-based-algorithm-and-a-variation1>Direction Based Algorithm and a Variation<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a><a hidden class=anchor aria-hidden=true href=#direction-based-algorithm-and-a-variation1>#</a></h2><p>This post describes a direction searching algorithm(<span class="math inline">\(\mathbf{x}_{k}\)</span>). And its variation gives a way to estimate step length (<span class="math inline">\(\alpha_k\)</span>).</p><h2 id=steepest-descent>Steepest Descent<a hidden class=anchor aria-hidden=true href=#steepest-descent>#</a></h2><p>To find the minimum points of a performance index by an iterative algorithm, we want to decrease the value of the performance index step by step which looks like going down from the top of the hill. And the crucial of this algorithm is that every iteration makes the performance index decrease:</p><p><span class="math display">\[
F(\mathbf{x}_{k+1})&lt;F(\mathbf{x}_{k})\tag{1}
\]</span></p><p>Our mission is to find the direction <span class="math inline">\(\mathbf{p}_k\)</span> with a relatively short step length <span class="math inline">\(\alpha_k\)</span> which leads us downhill.</p><p>The first-order Taylor series of an iterative step is:</p><p><span class="math display">\[
F(\mathbf{x}_{k+1})=F(\mathbf{x}_{k}+\Delta \mathbf{x}_k)\approx F(\mathbf{x}_{k})+\mathbf{g}^T\Delta\mathbf{x}_k\tag{2}
\]</span></p><p>where <span class="math inline">\(\mathbf{g}_k\)</span> is the gradient at position <span class="math inline">\(\mathbf{x}\)</span> of the performance index <span class="math inline">\(F(\mathbf{x})\)</span> which means:</p><p><span class="math display">\[
\mathbf{g}_k = \nabla F(\mathbf{x})\bigg |_{\mathbf{x}=\mathbf{x}_k}\tag{3}
\]</span></p><p>From equation(1) and equation(2) for the purpose <span class="math inline">\(F(\mathbf{x}_{k+1})&lt;F(\mathbf{x}_{k})\)</span>, we need:</p><p><span class="math display">\[
\mathbf{g}^T\Delta\mathbf{x}_k&lt;0\tag{4}
\]</span></p><p>( <span class="math inline">\(\Delta\mathbf{x}_k\)</span> , the change of <span class="math inline">\(\mathbf{x}_k\)</span>, can also be represented by step length <span class="math inline">\(\alpha_k\)</span> and direction <span class="math inline">\(\mathbf{p}\)</span>, then the equation(4) has a equivalent form:</p><p><span class="math display">\[
\alpha_k\mathbf{g}^T\Delta\mathbf{p}_k&lt;0\tag{5}
\]</span></p><p>In the previous posts, we have seen how to find the greatest value of <span class="math inline">\(\mathbf{g}^T\Delta\mathbf{p}_k\)</span>. And now we can find the smallest value of <span class="math inline">\(\mathbf{g}^T\Delta\mathbf{p}_k\)</span> in the same way. Then we got the smallest value is:</p><p><span class="math display">\[
-\mathbf{g}^T\mathbf{g}\tag{6}
\]</span></p><p>which means that the deepest direction we would search is:</p><p><span class="math display">\[
\Delta\mathbf{p}_k=-\mathbf{g}\tag{7}
\]</span></p><p>According to the iterative optimization algorithm framework in<a href>‘An Introduction to Performance Optimization’</a>, the second step is :</p><p><span class="math display">\[
\mathbf{x}_{k+1}=\mathbf{x}_{k}-\alpha_k\mathbf{g}_k\tag{8}
\]</span></p><p>The step length is also called the learning rate. And the choice of <span class="math inline">\(\alpha_k\)</span> can be:</p><ol type=1><li>Minimizing <span class="math inline">\(F(\mathbf{x})\)</span> with <span class="math inline">\(\alpha_k\)</span> by minimizing along the line: <span class="math inline">\(\mathbf{x}_k-\alpha_k\mathbf{g}_k\)</span></li><li>Fixed <span class="math inline">\(\alpha_k\)</span>, such as <span class="math inline">\(\alpha_k=0.002\)</span></li><li>Predetermined, like <span class="math inline">\(\alpha_k=\frac{1}{k}\)</span></li></ol><h3 id=an-example>An Example<a hidden class=anchor aria-hidden=true href=#an-example>#</a></h3><p><span class="math display">\[
F(\mathbf{x})=x_1^2+25x_2^2\tag{9}
\]</span></p><ol type=1><li>start at point <span class="math inline">\(x=\begin{bmatrix}0.5\\0.5\end{bmatrix}\)</span></li><li>gradient of <span class="math inline">\(F(\mathbf{x})\)</span> is <span class="math inline">\(\nabla F(\mathbf{x})=\begin{bmatrix}\frac{\partial F}{\partial x_1}\\\frac{\partial F}{\partial x_2}\end{bmatrix}=\begin{bmatrix}2x_1\\50x_2\end{bmatrix}\)</span></li><li><span class="math inline">\(\mathbf{g}_0=\nabla F(\mathbf{x})\bigg|_{\mathbf{x}=\mathbf{x}_0}=\begin{bmatrix}1\\25\end{bmatrix}\)</span></li><li>set <span class="math inline">\(\alpha = 0.01\)</span></li><li>update: <span class="math inline">\(\mathbf{x}_1=\mathbf{x}_0-0.01\mathbf{g}_0=\begin{bmatrix}0.5\\0.5\end{bmatrix}-0.01\begin{bmatrix}1\\25\end{bmatrix}=\begin{bmatrix}0.49\\0.25\end{bmatrix}\)</span></li><li>update: <span class="math inline">\(\mathbf{x}_2=\mathbf{x}_1-0.01\mathbf{g}_1=\begin{bmatrix}0.49\\0.25\end{bmatrix}-0.01\begin{bmatrix}0.98\\12.5\end{bmatrix}=\begin{bmatrix}0.4802\\0.125\end{bmatrix}\)</span></li><li>go on updating until the smallest point is achieved.</li></ol><p>The whole trajectory looks like this:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_54_contour_plot.png></p><p>and the learning rate, step length is a constant in this algorithm, however, we can test 2 different values and watch their behavior. When we set <span class="math inline">\(\alpha=0.01\)</span>, we have:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_54_lr_001.gif></p><p>and when we set <span class="math inline">\(\alpha=0.02\)</span>, we have: <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_54_lr_002.gif></p><p>These results illustrated:</p><ol type=1><li>In first several steps, the descent speed is faster than in later steps</li><li>A greater learning rate seems to have a higher speed</li><li>This algorithm can converge to the minimum point.</li></ol><p>The second point gives us a new idea, of what will the algorithms do when we have a relatively bigger learning rate. To be on the safe side we select a not so big learning rate <span class="math inline">\(\alpha=0.05\)</span>, we have:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_55_diverge.gif></p><p>this algorithm diverges, which means it would never stop at the minimum and get farther and farther as steps go on. So we have to take care of the value of the learning rate, a small learning rate can slow down the algorithm but a big one can break up the algorithm.</p><h2 id=stable-learning-rates>Stable Learning Rates<a hidden class=anchor aria-hidden=true href=#stable-learning-rates>#</a></h2><p>To have a fast speed and converge to the minimum, we need to study the learning rate <span class="math inline">\(\alpha\)</span>. To simplify the problem, we start with supposing the performance index is a quadratic function:</p><p><span class="math display">\[
F(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}+\mathbf{d}^T\mathbf{x}+c\tag{10}
\]</span></p><p>and we have already known its gradient is:</p><p><span class="math display">\[
\nabla F(\mathbf{x})=A \mathbf{x}+\mathbf{d}\tag{11}
\]</span></p><p>we take equation(11) into update step equation(8), we have:</p><p><span class="math display">\[
\mathbf{x}_{k+1}=\mathbf{x}_k-\alpha\mathbf{g}_k=\mathbf{x}_k-\alpha(A \mathbf{x}_k+\mathbf{d})\tag{12}
\]</span></p><p>or an equivalent form:</p><p><span class="math display">\[
\mathbf{x}_{k+1}=(I-\alpha A)\mathbf{x}_k - \alpha\mathbf{d}\tag{13}
\]</span></p><p>In the linear algebra course or other courses, this equation is called a ‘linear dynamic system’. To make the system stable, the eigenvalues of <span class="math inline">\(I-\alpha A\)</span> are less than one in magnitude. And <span class="math inline">\(I-\alpha A\)</span> has the same eigenvectors with <span class="math inline">\(A\)</span>. Let <span class="math inline">\([\lambda_1,\lambda_2,\cdots,\lambda_n]\)</span> be the eigenvalues of <span class="math inline">\(A\)</span> and let <span class="math inline">\([\mathbf{z}_1,\mathbf{z}_2,\cdots,\mathbf{z}_n]\)</span> be the eigenvectors of <span class="math inline">\(A\)</span></p><p><span class="math display">\[
[I-\alpha A]\mathbf{z}_i=\mathbf{z}_i-\alpha A\mathbf{z}_i=\mathbf{z}_i-\alpha \lambda_i\mathbf{z}_i=(1-\alpha\lambda_i)\mathbf{z}_i\tag{14}
\]</span></p><p><span class="math inline">\(I-\alpha A\)</span> has the same eigenvectors with <span class="math inline">\(A\)</span> and has the eigenvalues: <span class="math inline">\([1-\alpha\lambda_1,1-\alpha\lambda_2,\cdots,1-\alpha\lambda_n]\)</span></p><p>Concerning the equation(13) and eigenvalues of <span class="math inline">\(I-\alpha A\)</span> to stabilize the system which here is the steepest descent algorithm, we need:</p><p><span class="math display">\[
\begin{aligned}
&|1-\alpha \lambda_i|&&lt;1\\
-1&&lt;1-\alpha \lambda_i&&lt;1\\
-2&&lt;-\alpha \lambda_i&&lt;0\\
\end{aligned}\tag{15}
\]</span></p><p>for <span class="math inline">\(\alpha>0\)</span></p><p><span class="math display">\[
\begin{aligned}
\frac{2}{\alpha}&> \lambda_i&>0\\
\end{aligned}\tag{16}
\]</span></p><p>from equation(16), we finally have <span class="math display">\[
\frac{2}{\lambda_i}>\alpha\tag{17}
\]</span></p><p>which implies:</p><p><span class="math display">\[
\frac{2}{\lambda_{\text{max}}}>\alpha\tag{18}
\]</span></p><p>This gives us the maximum stable learning rate is inversely proportional to the maximum curvature(direction along with eigenvector according to the maximum eigenvalue <span class="math inline">\(\lambda_\text{max}\)</span>) of the quadratic function.</p><p>Let’s go back to the example, the Hessian matrix of the equation(9) is: <span class="math display">\[
A=\begin{bmatrix}
2&0\\0&50
\end{bmatrix}\tag{19}
\]</span></p><p>its eigenvectors and eigenvalues are: <span class="math display">\[
\{\lambda_1=2,\mathbf{z}_1=\begin{bmatrix}1\\0\end{bmatrix}\},\{\lambda_2=50,\mathbf{z}_2=\begin{bmatrix}0\\1\end{bmatrix}\}\tag{20}
\]</span></p><p>taking <span class="math inline">\(\lambda_\text{max}=\lambda_2=50\)</span> into equation(18), we get: <span class="math display">\[
\alpha_\text{max}&lt;\frac{2}{50}=0.04\tag{21}
\]</span></p><p>so, let’s check the behavior of the algorithm when <span class="math inline">\(\alpha=0.039\)</span> and <span class="math inline">\(\alpha=0.041\)</span>:</p><ol type=1><li>set <span class="math inline">\(\alpha=0.039\)</span> we have:<img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_55_lr_039.gif></li><li>set <span class="math inline">\(\alpha=0.041\)</span> we have:<img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_55_lr_041.gif></li></ol><p>Up to now, both concepts and implements have been built to prove the correctness of the algorithm. And we also have the following tips:</p><ol type=1><li>The algorithm tends to converge most quickly in the direction of the eigenvector corresponding to the largest eigenvalue</li><li>The algorithm tends to converge most slowly in the direction of the eigenvector corresponding to the smallest eigenvalue</li><li>Do not overshoot the minimum point for the too-long step(learning rate <span class="math inline">\(\alpha\)</span>)</li></ol><h2 id=minimizing-along-a-line>Minimizing along a Line<a hidden class=anchor aria-hidden=true href=#minimizing-along-a-line>#</a></h2><p>The section above gives us the upper bound of <span class="math inline">\(\alpha\)</span>, but we have three kinds of strategies for selecting a <span class="math inline">\(\alpha\)</span>.</p><p>The first one is “Minimizing <span class="math inline">\(F(\mathbf{x})\)</span> with <span class="math inline">\(\alpha_k\)</span> by minimizing along the line: <span class="math inline">\(\mathbf{x}_k-\alpha_k\mathbf{g}_k\)</span>”. What shall we do with this kind of <span class="math inline">\(\alpha\)</span>?</p><p>To arbitrary functions, the stationary point along a direction can be calculated by:</p><p><span class="math display">\[
\begin{aligned}
&\frac{dF}{d\alpha_k}(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\\
&=\nabla F(\mathbf{x})^T\bigg|_{\mathbf{x}=\mathbf{x}_k}\mathbf{p}_k+\alpha_k\mathbf{p}_k^T\nabla F^2(\mathbf{x})^T\bigg|_{\mathbf{x}=\mathbf{x}_k}\mathbf{p}_k\\
&=0
\end{aligned}\tag{22}
\]</span></p><p>and then</p><p><span class="math display">\[
\alpha=-\frac{\nabla F(\mathbf{x})^T\bigg|_{\mathbf{x}=\mathbf{x}_k}\mathbf{p}_k}{\mathbf{p}_k^T\nabla F^2(\mathbf{x})\bigg|_{\mathbf{x}=\mathbf{x}_k}\mathbf{p}_k}=-\frac{\mathbf{g}^T_k\mathbf{p}_k}{\mathbf{p}_k^TA_k\mathbf{p}_k}\tag{23}
\]</span></p><p>where: <span class="math inline">\(A_k\)</span> is the Hessian matrix of an old guess <span class="math inline">\(\mathbf{x}_k\)</span>:</p><p><span class="math display">\[
A_k=\nabla^2F(\mathbf{x})\bigg|_{\mathbf{x}=\mathbf{x}_k}\tag{24}
\]</span></p><p>Here we look at an example:</p><p><span class="math display">\[
F(x)=\frac{1}{2}\mathbf{x}^T\begin{bmatrix}
2&1\\1&2
\end{bmatrix}\mathbf{x}\tag{25}
\]</span></p><p>with the initial guess <span class="math display">\[
\mathbf{x}_0=\begin{bmatrix}0.8\\-0.25\end{bmatrix}\tag{26}
\]</span></p><p>the gradient of the function is</p><p><span class="math display">\[
\nabla F(\mathbf{x})=\begin{bmatrix}2x_1+x_2\\x_1+2x_2\end{bmatrix}\tag{27}
\]</span></p><p>the initial direction of the algorithm is</p><p><span class="math display">\[
\mathbf{p}_0=-\mathbf{g}_0=-\nabla F(\mathbf{x})\bigg|_{\mathbf{x}=\mathbf{x}_k}=\begin{bmatrix}-1.35\\-0.3\end{bmatrix}\tag{28}
\]</span></p><p>and take equation(28) and <span class="math inline">\(A=\begin{bmatrix}2&1\\1&2\end{bmatrix}\)</span> into equation(23): <span class="math display">\[
\alpha_0=\frac{\begin{bmatrix}1.35&0.3\end{bmatrix}\begin{bmatrix}2&1\\1&2\end{bmatrix}}{\begin{bmatrix}1.35&0.3\end{bmatrix}\begin{bmatrix}2&1\\1&2\end{bmatrix}\begin{bmatrix}1.35\\0.3\end{bmatrix}}=0.413\tag{29}
\]</span></p><p>and take all these data into equation(8):</p><p><span class="math display">\[
\mathbf{x}_1=\mathbf{x}_0-\alpha_0\mathbf{g}_0=\begin{bmatrix}0.8\\-0.25\end{bmatrix}-0.413\begin{bmatrix}1.35\\0.3\end{bmatrix}=\begin{bmatrix}0.24\\-0.37\end{bmatrix}\tag{30}
\]</span></p><p>What is going on is repeating the steps: equation(26) to equation(30) until some terminative conditions are achieved. It works like this:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_16_56_lr_mal.gif></p><p>All the new directions in the steps are orthogonal to their last direction:</p><p><span class="math display">\[
\mathbf{p}_{k+1}^T\mathbf{p}_k=\mathbf{g}_{k+1}^T\mathbf{p}_k=0\tag{31}
\]</span></p><p>what we need now is to proof is <span class="math inline">\(\mathbf{g}_{k+1}^T\mathbf{p}_k=0\)</span>, with the chain rule of equation(22):</p><p><span class="math display">\[
\begin{aligned}
\frac{d}{d\alpha_k}F(\mathbf{x}_{k+1})&=\frac{d}{d\alpha_k}F(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\\
&=\nabla F(\mathbf{x})^T\bigg|_{\mathbf{x}=\mathbf{x}_{k+1}}\frac{d}{d\alpha_k}(\mathbf{x}_k+\alpha_k\mathbf{p}_k)\\
&=\nabla F(\mathbf{x})^T\bigg|_{\mathbf{x}=\mathbf{x}_{k+1}}\mathbf{p}_k\\
&=0
\end{aligned}\tag{32}
\]</span></p><p>equation(32) gives us: a new direction is always orthogonal to the last step direction at the minimum point of the function along the last step direction. This is also an inspiration for another algorithm called conjugate direction.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p>Demuth, H.B., Beale, M.H., De Jess, O. and Hagan, M.T., 2014. Neural network design. Martin Hagan.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://anthony-tan.com/tags/artificial-neural-networks/>Artificial Neural Networks</a></li><li><a href=https://anthony-tan.com/tags/artificial-intelligence/>Artificial Intelligence</a></li><li><a href=https://anthony-tan.com/tags/steepest-descent/>Steepest Descent</a></li><li><a href=https://anthony-tan.com/tags/optimization/>optimization</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Steepest Descent Method on twitter" href="https://twitter.com/intent/tweet/?text=Steepest%20Descent%20Method&url=https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f&hashtags=ArtificialNeuralNetworks%2cArtificialIntelligence%2cSteepestDescent%2coptimization"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Steepest Descent Method on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f&title=Steepest%20Descent%20Method&summary=Steepest%20Descent%20Method&source=https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Steepest Descent Method on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f&title=Steepest%20Descent%20Method"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Steepest Descent Method on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Steepest Descent Method on whatsapp" href="https://api.whatsapp.com/send?text=Steepest%20Descent%20Method%20-%20https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Steepest Descent Method on telegram" href="https://telegram.me/share/url?text=Steepest%20Descent%20Method&url=https%3a%2f%2fanthony-tan.com%2fSteepest-Descent-Method%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><figure class=article-discussion><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//anthony-tan-com.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></figure></article></main><footer class=footer><span>&copy; 2022 <a href=https://anthony-tan.com>Anthony's Blogs</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>
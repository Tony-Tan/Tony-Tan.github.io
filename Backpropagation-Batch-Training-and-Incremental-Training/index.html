<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Backpropagation, Batch Training, and Incremental Training | Anthony's Blogs</title><meta name=keywords content="Artificial Neural Networks,Artificial Intelligence,backpropagation,batch training,incremental training,Backpropagation"><meta name=description content="Preliminaries Calculus 1,2 Linear Algebra  Batch v.s. Incremental Training1 In both LMS and BP algorithms, the error in each update process step is not MSE but SE \(e=t_i-a_i\) which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set."><meta name=author content="Anthony Tan"><link rel=canonical href=https://anthony-tan.com/Backpropagation-Batch-Training-and-Incremental-Training/><link crossorigin=anonymous href=../assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://anthony-tan.com/logo.png><link rel=apple-touch-icon href=https://anthony-tan.com/logo.png><link rel=mask-icon href=https://anthony-tan.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-12","auto"),ga("send","pageview"))</script><meta property="og:title" content="Backpropagation, Batch Training, and Incremental Training"><meta property="og:description" content="Preliminaries Calculus 1,2 Linear Algebra  Batch v.s. Incremental Training1 In both LMS and BP algorithms, the error in each update process step is not MSE but SE \(e=t_i-a_i\) which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set."><meta property="og:type" content="article"><meta property="og:url" content="https://anthony-tan.com/Backpropagation-Batch-Training-and-Incremental-Training/"><meta property="article:section" content="deep_learning"><meta property="article:published_time" content="2020-01-02T17:49:55+00:00"><meta property="article:modified_time" content="2022-05-03T10:39:43+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Backpropagation, Batch Training, and Incremental Training"><meta name=twitter:description content="Preliminaries Calculus 1,2 Linear Algebra  Batch v.s. Incremental Training1 In both LMS and BP algorithms, the error in each update process step is not MSE but SE \(e=t_i-a_i\) which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Deep Learning","item":"https://anthony-tan.com/deep_learning/"},{"@type":"ListItem","position":3,"name":"Backpropagation, Batch Training, and Incremental Training","item":"https://anthony-tan.com/Backpropagation-Batch-Training-and-Incremental-Training/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Backpropagation, Batch Training, and Incremental Training","name":"Backpropagation, Batch Training, and Incremental Training","description":"Preliminaries Calculus 1,2 Linear Algebra  Batch v.s. Incremental Training1 In both LMS and BP algorithms, the error in each update process step is not MSE but SE \\(e=t_i-a_i\\) which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set.","keywords":["Artificial Neural Networks","Artificial Intelligence","backpropagation","batch training","incremental training","Backpropagation"],"articleBody":"Preliminaries Calculus 1,2 Linear Algebra  Batch v.s. Incremental Training1 In both LMS and BP algorithms, the error in each update process step is not MSE but SE \\(e=t_i-a_i\\) which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set. It is also called ‘online’ learning when each time step a data point is used and ‘online’ data is always coming to us. And each one can be used independently by the algorithm. So incremental training is also a name for this process.\nWhen we use the whole data set to approximate the error, this is called batch training. This algorithm calculates gradient after all inputs are applied to the network before parameters are updated. For example, when all inputs have equal probability, the mean square error becomes:\n\\[ \\begin{aligned} F(\\mathbf{x})\u0026=\\mathbb E[\\mathbf{e}^T\\mathbf{e}]\\\\ \u0026=\\mathbb E[(\\mathbf{t}-\\mathbf{a})^T(\\mathbf{t}-\\mathbf{a})]\\\\ \u0026=\\frac{1}{Q}\\sum^{Q}_{q=1}(\\mathbf{t}_q-\\mathbf{a}_q)^T(\\mathbf{t}_q-\\mathbf{a}_q) \\end{aligned}\\tag{1} \\]\nRather than changing MSE into SE, this just replaced the MSE with the average of the whole training set error. A statistics professor at MIT said: ‘what our statisticians do every day is replacing expectation with average’. This average is closer to the MSE than SE is. Then the total gradient is:\n\\[ \\begin{aligned} \\nabla F(\\mathbf{x})\u0026=\\nabla\\{\\frac{1}{Q}\\sum^{Q}_{q=1}(\\mathbf{t}_q-\\mathbf{a}_q)^T(\\mathbf{t}_q-\\mathbf{a}_q)\\}\\\\ \u0026=\\frac{1}{Q}\\sum^{Q}_{q=1}\\nabla\\{(\\mathbf{t}_q-\\mathbf{a}_q)^T(\\mathbf{t}_q-\\mathbf{a}_q)\\} \\end{aligned}\\tag{2} \\]\nThen the update step is converted to:\n\\[ W^m(k+1)=W^m(k)-\\frac{\\alpha}{Q}\\sum^{Q}_{q=1}\\mathbf{s}^m_q(\\mathbf{a}^{m-1}_q)^T\\\\ \\mathbf{b}^m(k+1)=\\mathbf{b}^m(k)-\\frac{\\alpha}{Q}\\sum^{Q}_{q=1}\\mathbf{s}^m_q\\cdot 1\\tag{3} \\]\nUsing Backpropagation Building a toy BP program is a good way to go deeper inside the algorithm. The details of the design of the algorithm could be found in ‘The Backpropagation Algorithm’. And the task is consist of three essential parts:\nChoice of network architecture The algorithm used to train to a network would convergent Generalization  Choice of Network Architecture How many layers and how many neurons are necessary for a certain task is the key point in designing a network. For instance, to approximate the target functions\n\\[ g(p)=1+\\sin(\\frac{i\\pi}{4}\\cdot p)\\tag{4} \\]\nwhere for \\(-2\\leq p \\leq 2\\) and \\(i=\\{1,2,4,8\\}\\). And these four different functions look like:\nat the interval of \\([-2,2]\\)\n1-3-1 Neural Network The architecture we used here to approximate four functions is a 1-3-1 net. And the BP algorithm is used.\nThen the process of changing of the curve for \\(g(p)=1+\\sin(\\frac{\\pi}{4}\\cdot p)\\) is like:\nAnd for the \\(g(p)=1+\\sin(\\frac{2\\pi}{4}\\cdot p)\\)\nAnd for the \\(g(p)=1+\\sin(\\frac{4\\pi}{4}\\cdot p)\\) And for the \\(g(p)=1+\\sin(\\frac{8\\pi}{4}\\cdot p)\\) The four final approximate results of these for the function are: Limit of 1-3-1 network has been illustrated above and the capacity of 1-3-1 network can only approximate \\(g(p)=1+\\sin(\\frac{i\\pi}{4}\\cdot p)\\) for \\(i=\\{1,2,3,4\\}\\).\n\\(g(p)=1+\\sin(\\frac{8\\pi}{4}\\cdot p)\\) can not be regressed by 1-3-1 for its flexibility is not enough for the target function. This can also be concluded by the property of these three neurons in the hidden layer whose transfer function is log-sigmoid. Because these three neurons have only three ‘steps’(which has been described in ‘An Introduction to Backpropagation and Multilayer Perceptrons’). These three steps are trained to approximate the three crests of the target functions. So when the target functions have more than 3 crests (including 3 crests), 1-3-1 can not regress the target function accurately.\n1-2-1, 1-3-1, 1-4-1, 1-5-1 networks for \\(g(p)=1+\\sin(\\frac{6\\pi}{4}\\cdot p)\\) The target function \\(g(p)=1+\\sin(\\frac{6\\pi}{4}\\cdot p)\\) has 3 crests at iterval \\([-2,2]\\) and 4 different types of network are used in the approximation:\nThe process of 1-2-1 neuron network for \\(g(p)=1+\\sin(\\frac{6\\pi}{4}\\cdot p)\\) is like:\nThe process of 1-3-1 neuron network for \\(g(p)=1+\\sin(\\frac{6\\pi}{4}\\cdot p)\\) is like:\nThe process of 1-4-1 neuron network for \\(g(p)=1+\\sin(\\frac{6\\pi}{4}\\cdot p)\\) is like:\nThe process of 1-5-1 neuron network for \\(g(p)=1+\\sin(\\frac{6\\pi}{4}\\cdot p)\\) is like:\nAnd the final results of these four networks are:\nSummary of the comparison of the results of the four different networks are:\nthe more neurons in hidden layers the more flexible the entire network is if the flexibility of the network is not sufficient for the target function, it is not a good model for the task. although the flexibility of the network is sufficient, the training algorithm may also not be able to converge to the global minimum  Convergence Analysis When the training algorithm did not converge to the global minimum, the responses of the network can not give an accurate approximation to the desired function. This is just because the BP algorithm used here is not like LMS it worked under the condition that the performance index function is quadratic and it has only had one minimum. The performance index of multiple layers network has a lot of local minimum and saddle points also affect the convergence of the algorithm.\nBP can not guarantee convergence to the global minimum. Many factors can affect the process. And now let’s observe the different initial values of the parameters of the network which lead to different local minimums of the performance index:\nConvergent to a local minimum Initial values: |layer|neuron|initial weights and bias| |:—:|:—:|:—:| |2|1|\\([0.42965179 -0.07152415]\\)| |2|2|\\([0.16361572 0.79774829]\\)| |2|3|\\([0.73702272 0.75144977]\\)| |3|1|\\([0.76338542 0.95722099 -0.11531554 0.20356626]\\)|\nand the process of the algorithm is:\nthe descent process of MSE is:\nand the final converged parameters:\n  layer neuron initial weights and bias    2 1 \\([0.93900718 -0.01797782]\\)  2 2 \\([-4.82660011 4.52635542]\\)  2 3 \\([4.80297794 4.51769764]\\)  3 1 \\([13.6902581 5.32639145 -5.37517373 -5.8557322]\\)    Convergent to another local minimum Initial values: |layer|neuron|initial weights and bias| |:—:|:—:|:—:| |2|1|\\([-18.61882866 12.96283924]\\)| |2|2|\\([ 11.35841636 -20.15384594]\\)| |2|3|\\([ 2.77601854 22.87956077]\\)| |3|1|\\([-44.15374244 -58.65710547 -34.40432363 -78.4400726 ]\\)|\nand the process of the algorithm is:\nthe descent process of MSE is:\nand the final converged parameters:\n  layer neuron initial weights and bias    2 1 \\([-19.84672298 -21.74627601]\\)  2 2 \\([-31.5629279 -67.20354561]\\)  2 3 \\([2.77601496 22.8795743 ]\\)  3 1 \\([0.98462573 -47.6630436 22.41340957 -21.62233846]\\)    These two examples imply that the initial values of parameters primarily affect the local minimum the algorithm would converge to. not only the initial values but also other parameters of the learning algorithm would affect the final results.\nGeneralization For we have only a finite number of training samples(examples of proper network behavior) which means our task is approximating the function that has more input/output pairs than we used in training. And the behavior of the model to the inputs which were not used in the training process is called generalization. For instance, the target function is:\n\\[ g(p)=1+\\sin(\\frac{\\pi}{4}\\cdot p)\\tag{5} \\]\nand the training set are the inputs \\(p=-2.0,-1.6,\\cdots,1.6,2.0\\) and their corresponding outputs. These 11 pairs are used in training the following the two networks:\n1-2-1 1-2-1 gives a good generalization that is when the points are not used in the train, the blue line is also close to the red line:\n1-9-1 However, a more powerful network, a 1-9-1 network gives a closer approximation than the 1-2-1 network at training points that the blue circles are close to red circles. But at other points, which are not used in training, represented by the blue line is far from the ground truth. This means 1-9-1 gives a bad generalization:\nThis is called ‘overfitting’.\nthe summary of these two experiments is: 1. usually, parameters in the model should be less than the number of points in the training set(this can also be described as the number of training data should be more than the parameter in the model) 2. Ockham’s Razor is a good rule in future work of neuron network design: when the smaller networks could work, a bigger network is not necessary.\nReferences  Demuth, Howard B., Mark H. Beale, Orlando De Jess, and Martin T. Hagan. Neural network design. Martin Hagan, 2014.↩︎\n   ","wordCount":"1240","inLanguage":"en","datePublished":"2020-01-02T17:49:55Z","dateModified":"2022-05-03T10:39:43+08:00","author":{"@type":"Person","name":"Anthony Tan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://anthony-tan.com/Backpropagation-Batch-Training-and-Incremental-Training/"},"publisher":{"@type":"Organization","name":"Anthony's Blogs","logo":{"@type":"ImageObject","url":"https://anthony-tan.com/logo.png"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://anthony-tan.com accesskey=h title="Anthony's Blogs (Alt + H)">Anthony's Blogs</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://anthony-tan.com/machine_learning/ title="Machine Learning"><span>Machine Learning</span></a></li><li><a href=https://anthony-tan.com/deep_learning/ title="Deep Learning"><span>Deep Learning</span></a></li><li><a href=https://anthony-tan.com/reinforcement_learning/ title="Reinforcement Learning"><span>Reinforcement Learning</span></a></li><li><a href=https://anthony-tan.com/math/ title=Math><span>Math</span></a></li><li><a href=https://anthony-tan.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://anthony-tan.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://anthony-tan.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://anthony-tan.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://anthony-tan.com>Home</a>&nbsp;»&nbsp;<a href=https://anthony-tan.com/deep_learning/>Deep Learning</a></div><h1 class=post-title>Backpropagation, Batch Training, and Incremental Training</h1><div class=post-meta><span title="2020-01-02 17:49:55 +0000 UTC">January 2, 2020</span>&nbsp;·&nbsp;<span title="2022-05-03 10:39:43 +0800 +0800">(Last Modification: May 3, 2022)</span>&nbsp;·&nbsp;Anthony Tan</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#preliminaries aria-label=Preliminaries>Preliminaries</a></li><li><a href=#batch-v.s.-incremental-training1 aria-label="Batch v.s. Incremental Training1">Batch v.s. Incremental Training<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a></a></li><li><a href=#using-backpropagation aria-label="Using Backpropagation">Using Backpropagation</a><ul><li><a href=#choice-of-network-architecture aria-label="Choice of Network Architecture">Choice of Network Architecture</a></li><li><a href=#neural-network aria-label="1-3-1 Neural Network">1-3-1 Neural Network</a></li><li><a href=#networks-for-gp1sinfrac6pi4cdot-p aria-label="1-2-1, 1-3-1, 1-4-1, 1-5-1 networks for \(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)">1-2-1, 1-3-1, 1-4-1, 1-5-1 networks for <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span></a></li></ul></li><li><a href=#convergence-analysis aria-label="Convergence Analysis">Convergence Analysis</a><ul><li><a href=#convergent-to-a-local-minimum aria-label="Convergent to a local minimum">Convergent to a local minimum</a></li><li><a href=#convergent-to-another-local-minimum aria-label="Convergent to another local minimum">Convergent to another local minimum</a></li></ul></li><li><a href=#generalization aria-label=Generalization>Generalization</a><ul><li><a href=#section aria-label=1-2-1>1-2-1</a></li><li><a href=#section-1 aria-label=1-9-1>1-9-1</a></li></ul></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h2 id=preliminaries>Preliminaries<a hidden class=anchor aria-hidden=true href=#preliminaries>#</a></h2><ol type=1><li>Calculus 1,2</li><li>Linear Algebra</li></ol><h2 id=batch-v.s.-incremental-training1>Batch v.s. Incremental Training<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a><a hidden class=anchor aria-hidden=true href=#batch-v.s.-incremental-training1>#</a></h2><p>In both LMS and BP algorithms, the error in each update process step is not MSE but SE <span class="math inline">\(e=t_i-a_i\)</span> which is calculated just by a data point of the training set. This is called a stochastic gradient descent algorithm. And why it is called ‘stochastic’ is because error at every iterative step is approximated by randomly selected train data points but not the whole data set. It is also called ‘online’ learning when each time step a data point is used and ‘online’ data is always coming to us. And each one can be used independently by the algorithm. So incremental training is also a name for this process.</p><p>When we use the whole data set to approximate the error, this is called batch training. This algorithm calculates gradient after all inputs are applied to the network before parameters are updated. For example, when all inputs have equal probability, the mean square error becomes:</p><p><span class="math display">\[
\begin{aligned}
F(\mathbf{x})&=\mathbb E[\mathbf{e}^T\mathbf{e}]\\
&=\mathbb E[(\mathbf{t}-\mathbf{a})^T(\mathbf{t}-\mathbf{a})]\\
&=\frac{1}{Q}\sum^{Q}_{q=1}(\mathbf{t}_q-\mathbf{a}_q)^T(\mathbf{t}_q-\mathbf{a}_q)
\end{aligned}\tag{1}
\]</span></p><p>Rather than changing MSE into SE, this just replaced the MSE with the average of the whole training set error. A statistics professor at MIT said: ‘what our statisticians do every day is replacing expectation with average’. This average is closer to the MSE than SE is. Then the total gradient is:</p><p><span class="math display">\[
\begin{aligned}
\nabla F(\mathbf{x})&=\nabla\{\frac{1}{Q}\sum^{Q}_{q=1}(\mathbf{t}_q-\mathbf{a}_q)^T(\mathbf{t}_q-\mathbf{a}_q)\}\\
&=\frac{1}{Q}\sum^{Q}_{q=1}\nabla\{(\mathbf{t}_q-\mathbf{a}_q)^T(\mathbf{t}_q-\mathbf{a}_q)\}
\end{aligned}\tag{2}
\]</span></p><p>Then the update step is converted to:</p><p><span class="math display">\[
W^m(k+1)=W^m(k)-\frac{\alpha}{Q}\sum^{Q}_{q=1}\mathbf{s}^m_q(\mathbf{a}^{m-1}_q)^T\\
\mathbf{b}^m(k+1)=\mathbf{b}^m(k)-\frac{\alpha}{Q}\sum^{Q}_{q=1}\mathbf{s}^m_q\cdot 1\tag{3}
\]</span></p><h2 id=using-backpropagation>Using Backpropagation<a hidden class=anchor aria-hidden=true href=#using-backpropagation>#</a></h2><p>Building a toy BP program is a good way to go deeper inside the algorithm. The details of the design of the algorithm could be found in <a href=https://anthony-tan.com/The-Backpropagation-Algorithm/>‘The Backpropagation Algorithm’</a>. And the task is consist of three essential parts:</p><ol type=1><li>Choice of network architecture</li><li>The algorithm used to train to a network would convergent</li><li>Generalization</li></ol><h3 id=choice-of-network-architecture>Choice of Network Architecture<a hidden class=anchor aria-hidden=true href=#choice-of-network-architecture>#</a></h3><p>How many layers and how many neurons are necessary for a certain task is the key point in designing a network. For instance, to approximate the target functions</p><p><span class="math display">\[
g(p)=1+\sin(\frac{i\pi}{4}\cdot p)\tag{4}
\]</span></p><p>where for <span class="math inline">\(-2\leq p \leq 2\)</span> and <span class="math inline">\(i=\{1,2,4,8\}\)</span>. And these four different functions look like:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_07_generator.jpeg></p><p>at the interval of <span class="math inline">\([-2,2]\)</span></p><h3 id=neural-network>1-3-1 Neural Network<a hidden class=anchor aria-hidden=true href=#neural-network>#</a></h3><p>The architecture we used here to approximate four functions is a 1-3-1 net. And the BP algorithm is used.</p><p>Then the process of changing of the curve for <span class="math inline">\(g(p)=1+\sin(\frac{\pi}{4}\cdot p)\)</span> is like:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_07_bp-1-3-1-sin(pi_4_1).gif></p><p>And for the <span class="math inline">\(g(p)=1+\sin(\frac{2\pi}{4}\cdot p)\)</span></p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_07_bp-1-3-1-sin(pi_4_2).gif></p><p>And for the <span class="math inline">\(g(p)=1+\sin(\frac{4\pi}{4}\cdot p)\)</span> <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_07_bp-1-3-1-sin(pi_4_4).gif></p><p>And for the <span class="math inline">\(g(p)=1+\sin(\frac{8\pi}{4}\cdot p)\)</span> <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_08_bp-1-3-1-sin(pi_4_8).gif></p><p>The four final approximate results of these for the function are: <img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_08_1-3-1_approximations.jpeg></p><p>Limit of 1-3-1 network has been illustrated above and the capacity of 1-3-1 network can only approximate <span class="math inline">\(g(p)=1+\sin(\frac{i\pi}{4}\cdot p)\)</span> for <span class="math inline">\(i=\{1,2,3,4\}\)</span>.</p><p><span class="math inline">\(g(p)=1+\sin(\frac{8\pi}{4}\cdot p)\)</span> can not be regressed by 1-3-1 for its flexibility is not enough for the target function. This can also be concluded by the property of these three neurons in the hidden layer whose transfer function is log-sigmoid. Because these three neurons have only three ‘steps’(which has been described in <a href=https://anthony-tan.com/An-Introduction-to-Backpropagation-and-Multilayer-Perceptrons/>‘An Introduction to Backpropagation and Multilayer Perceptrons’</a>). These three steps are trained to approximate the three crests of the target functions. So when the target functions have more than 3 crests (including 3 crests), 1-3-1 can not regress the target function accurately.</p><h3 id=networks-for-gp1sinfrac6pi4cdot-p>1-2-1, 1-3-1, 1-4-1, 1-5-1 networks for <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span><a hidden class=anchor aria-hidden=true href=#networks-for-gp1sinfrac6pi4cdot-p>#</a></h3><p>The target function <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span> has 3 crests at iterval <span class="math inline">\([-2,2]\)</span> and 4 different types of network are used in the approximation:</p><p>The process of 1-2-1 neuron network for <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span> is like:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_08_1-2-1.gif></p><p>The process of 1-3-1 neuron network for <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span> is like:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_08_1-3-1.gif></p><p>The process of 1-4-1 neuron network for <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span> is like:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_08_1-4-1.gif></p><p>The process of 1-5-1 neuron network for <span class="math inline">\(g(p)=1+\sin(\frac{6\pi}{4}\cdot p)\)</span> is like:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_09_1-5-1.gif></p><p>And the final results of these four networks are:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_09_sin(pi_4_6)_result.jpeg></p><p>Summary of the comparison of the results of the four different networks are:</p><ol type=1><li>the more neurons in hidden layers the more flexible the entire network is</li><li>if the flexibility of the network is not sufficient for the target function, it is not a good model for the task.</li><li>although the flexibility of the network is sufficient, the training algorithm may also not be able to converge to the global minimum</li></ol><h2 id=convergence-analysis>Convergence Analysis<a hidden class=anchor aria-hidden=true href=#convergence-analysis>#</a></h2><p>When the training algorithm did not converge to the global minimum, the responses of the network can not give an accurate approximation to the desired function. This is just because the BP algorithm used here is not like LMS it worked under the condition that the performance index function is quadratic and it has only had one minimum. The performance index of multiple layers network has a lot of local minimum and saddle points also affect the convergence of the algorithm.</p><p>BP can not guarantee convergence to the global minimum. Many factors can affect the process. And now let’s observe the different initial values of the parameters of the network which lead to different local minimums of the performance index:</p><h3 id=convergent-to-a-local-minimum>Convergent to a local minimum<a hidden class=anchor aria-hidden=true href=#convergent-to-a-local-minimum>#</a></h3><p>Initial values: |layer|neuron|initial weights and bias| |:—:|:—:|:—:| |2|1|<span class="math inline">\([0.42965179 -0.07152415]\)</span>| |2|2|<span class="math inline">\([0.16361572 0.79774829]\)</span>| |2|3|<span class="math inline">\([0.73702272 0.75144977]\)</span>| |3|1|<span class="math inline">\([0.76338542 0.95722099 -0.11531554 0.20356626]\)</span>|</p><p>and the process of the algorithm is:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_09_convergence.gif></p><p>the descent process of MSE is:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_09_loss_convergence.png></p><p>and the final converged parameters:</p><table><thead><tr class=header><th style=text-align:center>layer</th><th style=text-align:center>neuron</th><th style=text-align:center>initial weights and bias</th></tr></thead><tbody><tr class=odd><td style=text-align:center>2</td><td style=text-align:center>1</td><td style=text-align:center><span class="math inline">\([0.93900718 -0.01797782]\)</span></td></tr><tr class=even><td style=text-align:center>2</td><td style=text-align:center>2</td><td style=text-align:center><span class="math inline">\([-4.82660011 4.52635542]\)</span></td></tr><tr class=odd><td style=text-align:center>2</td><td style=text-align:center>3</td><td style=text-align:center><span class="math inline">\([4.80297794 4.51769764]\)</span></td></tr><tr class=even><td style=text-align:center>3</td><td style=text-align:center>1</td><td style=text-align:center><span class="math inline">\([13.6902581 5.32639145 -5.37517373 -5.8557322]\)</span></td></tr></tbody></table><h3 id=convergent-to-another-local-minimum>Convergent to another local minimum<a hidden class=anchor aria-hidden=true href=#convergent-to-another-local-minimum>#</a></h3><p>Initial values: |layer|neuron|initial weights and bias| |:—:|:—:|:—:| |2|1|<span class="math inline">\([-18.61882866 12.96283924]\)</span>| |2|2|<span class="math inline">\([ 11.35841636 -20.15384594]\)</span>| |2|3|<span class="math inline">\([ 2.77601854 22.87956077]\)</span>| |3|1|<span class="math inline">\([-44.15374244 -58.65710547 -34.40432363 -78.4400726 ]\)</span>|</p><p>and the process of the algorithm is:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_10_nonconvergence.gif></p><p>the descent process of MSE is:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_10_loss_nonconvergence.png></p><p>and the final converged parameters:</p><table><thead><tr class=header><th style=text-align:center>layer</th><th style=text-align:center>neuron</th><th style=text-align:center>initial weights and bias</th></tr></thead><tbody><tr class=odd><td style=text-align:center>2</td><td style=text-align:center>1</td><td style=text-align:center><span class="math inline">\([-19.84672298 -21.74627601]\)</span></td></tr><tr class=even><td style=text-align:center>2</td><td style=text-align:center>2</td><td style=text-align:center><span class="math inline">\([-31.5629279 -67.20354561]\)</span></td></tr><tr class=odd><td style=text-align:center>2</td><td style=text-align:center>3</td><td style=text-align:center><span class="math inline">\([2.77601496 22.8795743 ]\)</span></td></tr><tr class=even><td style=text-align:center>3</td><td style=text-align:center>1</td><td style=text-align:center><span class="math inline">\([0.98462573 -47.6630436 22.41340957 -21.62233846]\)</span></td></tr></tbody></table><p>These two examples imply that the initial values of parameters primarily affect the local minimum the algorithm would converge to. not only the initial values but also other parameters of the learning algorithm would affect the final results.</p><h2 id=generalization>Generalization<a hidden class=anchor aria-hidden=true href=#generalization>#</a></h2><p>For we have only a finite number of training samples(examples of proper network behavior) which means our task is approximating the function that has more input/output pairs than we used in training. And the behavior of the model to the inputs which were not used in the training process is called generalization. For instance, the target function is:</p><p><span class="math display">\[
g(p)=1+\sin(\frac{\pi}{4}\cdot p)\tag{5}
\]</span></p><p>and the training set are the inputs <span class="math inline">\(p=-2.0,-1.6,\cdots,1.6,2.0\)</span> and their corresponding outputs. These 11 pairs are used in training the following the two networks:</p><h3 id=section>1-2-1<a hidden class=anchor aria-hidden=true href=#section>#</a></h3><p>1-2-1 gives a good generalization that is when the points are not used in the train, the blue line is also close to the red line:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_10_generalization_good.gif></p><h3 id=section-1>1-9-1<a hidden class=anchor aria-hidden=true href=#section-1>#</a></h3><p>However, a more powerful network, a 1-9-1 network gives a closer approximation than the 1-2-1 network at training points that the blue circles are close to red circles. But at other points, which are not used in training, represented by the blue line is far from the ground truth. This means 1-9-1 gives a bad generalization:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_02_17_10_generalization_bad.gif></p><p>This is called ‘overfitting’.</p><p>the summary of these two experiments is: 1. usually, parameters in the model should be less than the number of points in the training set(this can also be described as the number of training data should be more than the parameter in the model) 2. Ockham’s Razor is a good rule in future work of neuron network design: when the smaller networks could work, a bigger network is not necessary.</p><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p>Demuth, Howard B., Mark H. Beale, Orlando De Jess, and Martin T. Hagan. Neural network design. Martin Hagan, 2014.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://anthony-tan.com/tags/artificial-neural-networks/>Artificial Neural Networks</a></li><li><a href=https://anthony-tan.com/tags/artificial-intelligence/>Artificial Intelligence</a></li><li><a href=https://anthony-tan.com/tags/batch-training/>batch training</a></li><li><a href=https://anthony-tan.com/tags/incremental-training/>incremental training</a></li><li><a href=https://anthony-tan.com/tags/backpropagation/>backpropagation</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Backpropagation, Batch Training, and Incremental Training on twitter" href="https://twitter.com/intent/tweet/?text=Backpropagation%2c%20Batch%20Training%2c%20and%20Incremental%20Training&url=https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f&hashtags=ArtificialNeuralNetworks%2cArtificialIntelligence%2cbackpropagation%2cbatchtraining%2cincrementaltraining%2cBackpropagation"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Backpropagation, Batch Training, and Incremental Training on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f&title=Backpropagation%2c%20Batch%20Training%2c%20and%20Incremental%20Training&summary=Backpropagation%2c%20Batch%20Training%2c%20and%20Incremental%20Training&source=https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Backpropagation, Batch Training, and Incremental Training on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f&title=Backpropagation%2c%20Batch%20Training%2c%20and%20Incremental%20Training"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Backpropagation, Batch Training, and Incremental Training on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Backpropagation, Batch Training, and Incremental Training on whatsapp" href="https://api.whatsapp.com/send?text=Backpropagation%2c%20Batch%20Training%2c%20and%20Incremental%20Training%20-%20https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Backpropagation, Batch Training, and Incremental Training on telegram" href="https://telegram.me/share/url?text=Backpropagation%2c%20Batch%20Training%2c%20and%20Incremental%20Training&url=https%3a%2f%2fanthony-tan.com%2fBackpropagation-Batch-Training-and-Incremental-Training%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><figure class=article-discussion><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//anthony-tan-com.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></figure></article></main><footer class=footer><span>&copy; 2022 <a href=https://anthony-tan.com>Anthony's Blogs</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>
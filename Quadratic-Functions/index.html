<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Quadratic Functions | Anthony's Blogs</title><meta name=keywords content="Artificial Neural Networks,Artificial Intelligence,Quadratic Functions,Hessian matrix,eigenvalues,eigenvectors,Taylor series"><meta name=description content="Preliminaries Linear algebra Calculus 1,2 Taylor series  Quadratic Functions1 Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.
\[ F(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}+\mathbf{d}\mathbf{x}+c\tag{1} \]
where \(A\) is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:
\[ \nabla (\mathbf{h}^T\mathbf{x})=\nabla (\mathbf{x}^T\mathbf{h})=\mathbf{h}\tag{2} \]
and
\[ \nabla (\mathbf{x}^TQ\mathbf{x})=Q\mathbf{x}+Q^T\mathbf{x}=2Q\mathbf{x}\tag{3} \]"><meta name=author content="Anthony Tan"><link rel=canonical href=https://anthony-tan.com/Quadratic-Functions/><link crossorigin=anonymous href=../assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=../assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=16x16 href=https://anthony-tan.com/logo.png><link rel=icon type=image/png sizes=32x32 href=https://anthony-tan.com/logo.png><link rel=apple-touch-icon href=https://anthony-tan.com/logo.png><link rel=mask-icon href=https://anthony-tan.com/logo.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,o,i,a,t,n,s){e.GoogleAnalyticsObject=t,e[t]=e[t]||function(){(e[t].q=e[t].q||[]).push(arguments)},e[t].l=1*new Date,n=o.createElement(i),s=o.getElementsByTagName(i)[0],n.async=1,n.src=a,s.parentNode.insertBefore(n,s)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-105335860-12","auto"),ga("send","pageview"))</script><meta property="og:title" content="Quadratic Functions"><meta property="og:description" content="Preliminaries Linear algebra Calculus 1,2 Taylor series  Quadratic Functions1 Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.
\[ F(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}+\mathbf{d}\mathbf{x}+c\tag{1} \]
where \(A\) is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:
\[ \nabla (\mathbf{h}^T\mathbf{x})=\nabla (\mathbf{x}^T\mathbf{h})=\mathbf{h}\tag{2} \]
and
\[ \nabla (\mathbf{x}^TQ\mathbf{x})=Q\mathbf{x}+Q^T\mathbf{x}=2Q\mathbf{x}\tag{3} \]"><meta property="og:type" content="article"><meta property="og:url" content="https://anthony-tan.com/Quadratic-Functions/"><meta property="article:section" content="deep_learning"><meta property="article:published_time" content="2019-12-19T15:45:37+00:00"><meta property="article:modified_time" content="2022-05-01T22:45:32+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Quadratic Functions"><meta name=twitter:description content="Preliminaries Linear algebra Calculus 1,2 Taylor series  Quadratic Functions1 Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.
\[ F(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}+\mathbf{d}\mathbf{x}+c\tag{1} \]
where \(A\) is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:
\[ \nabla (\mathbf{h}^T\mathbf{x})=\nabla (\mathbf{x}^T\mathbf{h})=\mathbf{h}\tag{2} \]
and
\[ \nabla (\mathbf{x}^TQ\mathbf{x})=Q\mathbf{x}+Q^T\mathbf{x}=2Q\mathbf{x}\tag{3} \]"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Deep Learning","item":"https://anthony-tan.com/deep_learning/"},{"@type":"ListItem","position":3,"name":"Quadratic Functions","item":"https://anthony-tan.com/Quadratic-Functions/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Quadratic Functions","name":"Quadratic Functions","description":"Preliminaries Linear algebra Calculus 1,2 Taylor series  Quadratic Functions1 Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.\n\\[ F(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^TA\\mathbf{x}+\\mathbf{d}\\mathbf{x}+c\\tag{1} \\]\nwhere \\(A\\) is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:\n\\[ \\nabla (\\mathbf{h}^T\\mathbf{x})=\\nabla (\\mathbf{x}^T\\mathbf{h})=\\mathbf{h}\\tag{2} \\]\nand\n\\[ \\nabla (\\mathbf{x}^TQ\\mathbf{x})=Q\\mathbf{x}+Q^T\\mathbf{x}=2Q\\mathbf{x}\\tag{3} \\]","keywords":["Artificial Neural Networks","Artificial Intelligence","Quadratic Functions","Hessian matrix","eigenvalues","eigenvectors","Taylor series"],"articleBody":"Preliminaries Linear algebra Calculus 1,2 Taylor series  Quadratic Functions1 Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.\n\\[ F(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^TA\\mathbf{x}+\\mathbf{d}\\mathbf{x}+c\\tag{1} \\]\nwhere \\(A\\) is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:\n\\[ \\nabla (\\mathbf{h}^T\\mathbf{x})=\\nabla (\\mathbf{x}^T\\mathbf{h})=\\mathbf{h}\\tag{2} \\]\nand\n\\[ \\nabla (\\mathbf{x}^TQ\\mathbf{x})=Q\\mathbf{x}+Q^T\\mathbf{x}=2Q\\mathbf{x}\\tag{3} \\]\nthen the first order of quadratic functions are:\n\\[ \\nabla F(\\mathbf{x})=A\\mathbf{x}+\\mathbf{d}\\tag{4} \\]\nand second-order of quadratic functions are: \\[ \\nabla^2 F(\\mathbf{x})=A\\tag{5} \\]\nThe shape of quadratic functions can be described by eigenvalues and eigenvectors of its Hessian matrix. Hessian matrix is a symmetric matrix and its eigenvectors are mutually orthogonal, let:\n\\[ \\mathbf{z}_1,\\mathbf{z}_2,\\cdots ,\\mathbf{z}_n\\tag{6} \\]\ndenote the whole set of the eigenvectors of the Hessian matrix \\(A\\) and we build a matrix:\n\\[ B=\\begin{bmatrix} \\mathbf{z}_1\u0026\\mathbf{z}_2\u0026\\cdots \u0026\\mathbf{z}_n \\end{bmatrix}\\tag{7} \\]\nand because of \\(BB^T=I\\), we have \\(B^{-1}=B^T\\). When the Hessian matrix is positive definite, it would have \\(n\\) eigenvectors(Hessian has a full rank \\(n\\)) and we can change the Hessian matrix into a new matrix whose basis are the set of eigenvectors:\n\\[ A'=B^TAB=\\begin{bmatrix} \\lambda_1\u0026\u0026\u0026\\\\ \u0026\\lambda_2\u0026\u0026\\\\ \u0026\u0026\\ddots\u0026\\\\ \u0026\u0026\u0026\\lambda_n \\end{bmatrix}=\\Lambda\\tag{8} \\]\nafter changing the basis, the new Hessian matrix is a diagonal matrix whose elements on the diagonal are the eigenvalues. This process can be inversed because of \\(BB^T=I\\):\n\\[ A=BA'B^T=B\\Lambda B^T\\tag{9} \\]\nWe can calculate the derivative in any directions:\n\\[ \\frac{\\mathbf{p}^T\\nabla^2 F(\\mathbf{x})\\mathbf{p}}{||\\mathbf{p}||^2}=\\frac{\\mathbf{p}^TA\\mathbf{p}}{||\\mathbf{p}||^2}\\tag{10} \\]\nFor columns of \\(B\\) can span the whole space, So we can find a vector \\(\\mathbf{c}\\) satisfy:\n\\[ \\mathbf{p}=B\\mathbf{c}\\tag{11} \\]\nthen take equation(8), equation(11) into equation(10) we get:\n\\[ \\frac{\\mathbf{c}^TB^TAB\\mathbf{c}}{\\mathbf{c}^TB^TB\\mathbf{c}}=\\frac{\\mathbf{c}^T\\Lambda\\mathbf{c}}{\\mathbf{c}^TI\\mathbf{c}}=\\frac{\\sum^n_{i=1}\\lambda_i c_i^2}{\\sum_{i=1}^n c^2_i}\\tag{12} \\]\nFrom equation(12), we could conclude:\n\\[ \\lambda_{\\text{min}}\\leq \\frac{\\mathbf{p}^TA\\mathbf{p}}{||\\mathbf{p}||^2}\\leq \\lambda_{\\text{max}}\\tag{13} \\]\nmaximum \\(2^{\\text{nd}}\\) derivative occure along with \\(\\mathbf{z}_{\\text{max}}\\)(according to \\(\\lambda_{\\text{max}}\\)) eigenvalues is the \\(2^{\\text{nd}}\\) derivative along its eigenvector. eigenvectors could define a new coordinate system eigenvectors are principal axes of the function contour. going along with the \\(\\mathbf{z}_{\\text{max}}\\) direction could have the largest change in function value \\(|\\Delta F(x)|\\) eigenvalues here are all positive because of positive definite.  An example:\n\\[ F(\\mathbf{x})=x_1^2+x_1x_2+x_2^2 =\\frac{1}{2}\\mathbf{x}^T \\begin{bmatrix} 2\u00261\\\\1\u00262 \\end{bmatrix}\\mathbf{x}\\tag{14} \\]\nwe can calculate the eigenvectors and eigenvalues:\n\\[ \\begin{aligned} \u0026\\lambda_1=1\u0026\u0026\\mathbf{z}_1=\\begin{bmatrix} 1\\\\-1 \\end{bmatrix}\\\\ \u0026\\lambda_2=3\u0026\u0026\\mathbf{z}_2=\\begin{bmatrix} 1\\\\1 \\end{bmatrix} \\end{aligned}\\tag{15} \\]\nThe contour plot and 3-D plots are:\nAnother example:\n\\[ F(\\mathbf{x})=-\\frac{1}{4}x_1^2-\\frac{3}{2}x_1x_2-\\frac{1}{4}x_2^2 =\\frac{1}{2}\\mathbf{x}^T \\begin{bmatrix} -0.5\u0026-1.5\\\\-1.5\u0026-0.5 \\end{bmatrix}\\mathbf{x}\\tag{16} \\]\nwe can calculate the eigenvectors and eigenvalues:\n\\[ \\begin{aligned} \u0026\\lambda_1=1\u0026\u0026\\mathbf{z}_1=\\begin{bmatrix} -1\\\\1 \\end{bmatrix}\\\\ \u0026\\lambda_2=-2\u0026\u0026\\mathbf{z}_2=\\begin{bmatrix} -1\\\\-1 \\end{bmatrix} \\end{aligned}\\tag{17} \\]\nThe contour plot and 3-D plots is:\nConclusion \\(\\lambda_i0\\) or \\(i=1,2,\\cdots\\), \\(F(x)\\) have a single strong minimum \\(\\lambda_i or \\(i=1,2,\\cdots\\), \\(F(x)\\) have a single strong maximum \\(\\lambda_i\\) have both negative and positive together. \\(F(x)\\) has a saddle point \\(\\lambda_i\\geq 0\\) and have a \\(\\lambda_j=0\\), \\(F(x)\\) has a weak minimum or has no stationary point. \\(\\lambda_i\\leq 0\\) and have a \\(\\lambda_j=0\\), \\(F(x)\\) has a weak maximum or has no stationary point.  References  Demuth, H.B., Beale, M.H., De Jess, O. and Hagan, M.T., 2014. Neural network design. Martin Hagan.↩︎\n   ","wordCount":"489","inLanguage":"en","datePublished":"2019-12-19T15:45:37Z","dateModified":"2022-05-01T22:45:32+08:00","author":{"@type":"Person","name":"Anthony Tan"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://anthony-tan.com/Quadratic-Functions/"},"publisher":{"@type":"Organization","name":"Anthony's Blogs","logo":{"@type":"ImageObject","url":"https://anthony-tan.com/logo.png"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js onload=renderMathInElement(document.body)></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://anthony-tan.com accesskey=h title="Anthony's Blogs (Alt + H)">Anthony's Blogs</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://anthony-tan.com/machine_learning/ title="Machine Learning"><span>Machine Learning</span></a></li><li><a href=https://anthony-tan.com/deep_learning/ title="Deep Learning"><span>Deep Learning</span></a></li><li><a href=https://anthony-tan.com/reinforcement_learning/ title="Reinforcement Learning"><span>Reinforcement Learning</span></a></li><li><a href=https://anthony-tan.com/math/ title=Math><span>Math</span></a></li><li><a href=https://anthony-tan.com/archives title=Archive><span>Archive</span></a></li><li><a href=https://anthony-tan.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://anthony-tan.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://anthony-tan.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://anthony-tan.com>Home</a>&nbsp;»&nbsp;<a href=https://anthony-tan.com/deep_learning/>Deep Learning</a></div><h1 class=post-title>Quadratic Functions</h1><div class=post-meta><span title="2019-12-19 15:45:37 +0000 UTC">December 19, 2019</span>&nbsp;·&nbsp;<span title="2022-05-01 22:45:32 +0800 +0800">(Last Modification: May 1, 2022)</span>&nbsp;·&nbsp;Anthony Tan</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#preliminaries aria-label=Preliminaries>Preliminaries</a></li><li><a href=#quadratic-functions1 aria-label="Quadratic Functions1">Quadratic Functions<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a></a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li><li><a href=#references aria-label=References>References</a></li></ul></div></details></div><div class=post-content><h2 id=preliminaries>Preliminaries<a hidden class=anchor aria-hidden=true href=#preliminaries>#</a></h2><ol type=1><li>Linear algebra</li><li>Calculus 1,2</li><li>Taylor series</li></ol><h2 id=quadratic-functions1>Quadratic Functions<a href=#fn1 class=footnote-ref id=fnref1 role=doc-noteref><sup>1</sup></a><a hidden class=anchor aria-hidden=true href=#quadratic-functions1>#</a></h2><p>Quadratic function, a type of performance index, is universal. One of its key properties is that it can be represented in a second-order Taylor series precisely.</p><p><span class="math display">\[
F(\mathbf{x})=\frac{1}{2}\mathbf{x}^TA\mathbf{x}+\mathbf{d}\mathbf{x}+c\tag{1}
\]</span></p><p>where <span class="math inline">\(A\)</span> is a symmetric matrix(if it is not symmetric, it can be easily converted into symmetric). And recall the property of gradient:</p><p><span class="math display">\[
\nabla (\mathbf{h}^T\mathbf{x})=\nabla (\mathbf{x}^T\mathbf{h})=\mathbf{h}\tag{2}
\]</span></p><p>and</p><p><span class="math display">\[
\nabla (\mathbf{x}^TQ\mathbf{x})=Q\mathbf{x}+Q^T\mathbf{x}=2Q\mathbf{x}\tag{3}
\]</span></p><p>then the first order of quadratic functions are:</p><p><span class="math display">\[
\nabla F(\mathbf{x})=A\mathbf{x}+\mathbf{d}\tag{4}
\]</span></p><p>and second-order of quadratic functions are: <span class="math display">\[
\nabla^2 F(\mathbf{x})=A\tag{5}
\]</span></p><p>The shape of quadratic functions can be described by eigenvalues and eigenvectors of its <strong>Hessian matrix</strong>. <strong>Hessian matrix</strong> is a symmetric matrix and its eigenvectors are mutually orthogonal, let:</p><p><span class="math display">\[
\mathbf{z}_1,\mathbf{z}_2,\cdots ,\mathbf{z}_n\tag{6}
\]</span></p><p>denote the whole set of the eigenvectors of the Hessian matrix <span class="math inline">\(A\)</span> and we build a matrix:</p><p><span class="math display">\[
B=\begin{bmatrix}
\mathbf{z}_1&\mathbf{z}_2&\cdots &\mathbf{z}_n
\end{bmatrix}\tag{7}
\]</span></p><p>and because of <span class="math inline">\(BB^T=I\)</span>, we have <span class="math inline">\(B^{-1}=B^T\)</span>. When the Hessian matrix is positive definite, it would have <span class="math inline">\(n\)</span> eigenvectors(Hessian has a full rank <span class="math inline">\(n\)</span>) and we can change the Hessian matrix into a new matrix whose basis are the set of eigenvectors:</p><p><span class="math display">\[
A'=B^TAB=\begin{bmatrix}
\lambda_1&&&\\
&\lambda_2&&\\
&&\ddots&\\
&&&\lambda_n
\end{bmatrix}=\Lambda\tag{8}
\]</span></p><p>after changing the basis, the new Hessian matrix is a diagonal matrix whose elements on the diagonal are the eigenvalues. This process can be inversed because of <span class="math inline">\(BB^T=I\)</span>:</p><p><span class="math display">\[
A=BA'B^T=B\Lambda B^T\tag{9}
\]</span></p><p>We can calculate the derivative in any directions:</p><p><span class="math display">\[
\frac{\mathbf{p}^T\nabla^2 F(\mathbf{x})\mathbf{p}}{||\mathbf{p}||^2}=\frac{\mathbf{p}^TA\mathbf{p}}{||\mathbf{p}||^2}\tag{10}
\]</span></p><p>For columns of <span class="math inline">\(B\)</span> can span the whole space, So we can find a vector <span class="math inline">\(\mathbf{c}\)</span> satisfy:</p><p><span class="math display">\[
\mathbf{p}=B\mathbf{c}\tag{11}
\]</span></p><p>then take equation(8), equation(11) into equation(10) we get:</p><p><span class="math display">\[
\frac{\mathbf{c}^TB^TAB\mathbf{c}}{\mathbf{c}^TB^TB\mathbf{c}}=\frac{\mathbf{c}^T\Lambda\mathbf{c}}{\mathbf{c}^TI\mathbf{c}}=\frac{\sum^n_{i=1}\lambda_i c_i^2}{\sum_{i=1}^n c^2_i}\tag{12}
\]</span></p><p>From equation(12), we could conclude:</p><p><span class="math display">\[
\lambda_{\text{min}}\leq \frac{\mathbf{p}^TA\mathbf{p}}{||\mathbf{p}||^2}\leq \lambda_{\text{max}}\tag{13}
\]</span></p><ol type=1><li>maximum <span class="math inline">\(2^{\text{nd}}\)</span> derivative occure along with <span class="math inline">\(\mathbf{z}_{\text{max}}\)</span>(according to <span class="math inline">\(\lambda_{\text{max}}\)</span>)</li><li>eigenvalues is the <span class="math inline">\(2^{\text{nd}}\)</span> derivative along its eigenvector.</li><li>eigenvectors could define a new coordinate system</li><li>eigenvectors are principal axes of the function contour.</li><li>going along with the <span class="math inline">\(\mathbf{z}_{\text{max}}\)</span> direction could have the largest change in function value <span class="math inline">\(|\Delta F(x)|\)</span></li><li>eigenvalues here are all positive because of positive definite.</li></ol><p>An example:</p><p><span class="math display">\[
F(\mathbf{x})=x_1^2+x_1x_2+x_2^2
=\frac{1}{2}\mathbf{x}^T
\begin{bmatrix}
2&1\\1&2
\end{bmatrix}\mathbf{x}\tag{14}
\]</span></p><p>we can calculate the eigenvectors and eigenvalues:</p><p><span class="math display">\[
\begin{aligned}
&\lambda_1=1&&\mathbf{z}_1=\begin{bmatrix}
1\\-1
\end{bmatrix}\\
&\lambda_2=3&&\mathbf{z}_2=\begin{bmatrix}
1\\1
\end{bmatrix}
\end{aligned}\tag{15}
\]</span></p><p>The contour plot and 3-D plots are:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_01_22_40_contour_1.jpeg></p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_01_22_41_3_D_1.gif></p><p>Another example:</p><p><span class="math display">\[
F(\mathbf{x})=-\frac{1}{4}x_1^2-\frac{3}{2}x_1x_2-\frac{1}{4}x_2^2
=\frac{1}{2}\mathbf{x}^T
\begin{bmatrix}
-0.5&-1.5\\-1.5&-0.5
\end{bmatrix}\mathbf{x}\tag{16}
\]</span></p><p>we can calculate the eigenvectors and eigenvalues:</p><p><span class="math display">\[
\begin{aligned}
&\lambda_1=1&&\mathbf{z}_1=\begin{bmatrix}
-1\\1
\end{bmatrix}\\
&\lambda_2=-2&&\mathbf{z}_2=\begin{bmatrix}
-1\\-1
\end{bmatrix}
\end{aligned}\tag{17}
\]</span></p><p>The contour plot and 3-D plots is:</p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_01_22_40_contour_2.jpeg></p><p><img src=https://raw.githubusercontent.com/Tony-Tan/picgo_images_bed/master/2022_05_01_22_44_3_D_2.gif></p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><ol type=1><li><span class="math inline">\(\lambda_i>0\)</span> or <span class="math inline">\(i=1,2,\cdots\)</span>, <span class="math inline">\(F(x)\)</span> have a single strong minimum</li><li><span class="math inline">\(\lambda_i&lt;0\)</span> or <span class="math inline">\(i=1,2,\cdots\)</span>, <span class="math inline">\(F(x)\)</span> have a single strong maximum</li><li><span class="math inline">\(\lambda_i\)</span> have both negative and positive together. <span class="math inline">\(F(x)\)</span> has a saddle point</li><li><span class="math inline">\(\lambda_i\geq 0\)</span> and have a <span class="math inline">\(\lambda_j=0\)</span>, <span class="math inline">\(F(x)\)</span> has a weak minimum or has no stationary point.</li><li><span class="math inline">\(\lambda_i\leq 0\)</span> and have a <span class="math inline">\(\lambda_j=0\)</span>, <span class="math inline">\(F(x)\)</span> has a weak maximum or has no stationary point.</li></ol><h2 id=references>References<a hidden class=anchor aria-hidden=true href=#references>#</a></h2><section class=footnotes role=doc-endnotes><hr><ol><li id=fn1 role=doc-endnote><p>Demuth, H.B., Beale, M.H., De Jess, O. and Hagan, M.T., 2014. Neural network design. Martin Hagan.<a href=#fnref1 class=footnote-back role=doc-backlink>↩︎</a></p></li></ol></section></div><footer class=post-footer><ul class=post-tags><li><a href=https://anthony-tan.com/tags/artificial-neural-networks/>Artificial Neural Networks</a></li><li><a href=https://anthony-tan.com/tags/artificial-intelligence/>Artificial Intelligence</a></li><li><a href=https://anthony-tan.com/tags/quadratic-functions/>Quadratic Functions</a></li><li><a href=https://anthony-tan.com/tags/hessian-matrix/>Hessian matrix</a></li><li><a href=https://anthony-tan.com/tags/eigenvalues/>eigenvalues</a></li><li><a href=https://anthony-tan.com/tags/eigenvectors/>eigenvectors</a></li><li><a href=https://anthony-tan.com/tags/taylor-series/>Taylor series</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Quadratic Functions on twitter" href="https://twitter.com/intent/tweet/?text=Quadratic%20Functions&url=https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f&hashtags=ArtificialNeuralNetworks%2cArtificialIntelligence%2cQuadraticFunctions%2cHessianmatrix%2ceigenvalues%2ceigenvectors%2cTaylorseries"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Quadratic Functions on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f&title=Quadratic%20Functions&summary=Quadratic%20Functions&source=https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Quadratic Functions on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f&title=Quadratic%20Functions"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Quadratic Functions on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Quadratic Functions on whatsapp" href="https://api.whatsapp.com/send?text=Quadratic%20Functions%20-%20https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Quadratic Functions on telegram" href="https://telegram.me/share/url?text=Quadratic%20Functions&url=https%3a%2f%2fanthony-tan.com%2fQuadratic-Functions%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><figure class=article-discussion><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//anthony-tan-com.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></figure></article></main><footer class=footer><span>&copy; 2022 <a href=https://anthony-tan.com>Anthony's Blogs</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>
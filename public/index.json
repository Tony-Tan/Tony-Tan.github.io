[{"content":"Preliminaries Linear Algebra(the concepts of space, vector) Calculus  What is Linear Regression Linear regression is a basic idea in statistical and machine learning based on the linear combination. And it was usually used to predict some responses to some inputs(predictors).\nMachine Learning and Statistical Learning Machine learning and statistical learning are similar but have some distinctions. In machine learning, models, regression models, or classification models, are used to predict the outputs of the new incoming inputs.\nIn contrast, in statistical learning, regression and classification are employed to model the data to find out the hidden relations among the inputs. In other words, the models of data, no matter they are regression or classification, or something else. They are used to analyze the mechanism behind the data.\n‚ÄúLinear‚Äù Linear is a property of the operation \\(f(\\cdot)\\), which has the following two properties:\n\\(f(a\\mathbf{x})=af(\\mathbf{x})\\) \\(f(\\mathbf{x}+\\mathbf{y})=f(\\mathbf{x})+f(\\mathbf{y})\\)  where \\(a\\) is a scalar. Then we say \\(f(\\cdot)\\) is linear or \\(f(\\cdot)\\) has a linearity property.\nThe linear operation can be represented as a matrix. And when a 2-dimensional linear operation was drawn on the paper, it is a line. Maybe that is why it is named linear, I guess.\n‚ÄúRegression‚Äù In statistical or machine learning, regression is a crucial part of the whole field. And, the other part is the well-known classification. If we have a close look at the outputs data type, one distinction between them is that the output of regression is continuous but the output of classification is discrete.\nWhat is linear regression Linear regression is a regression model. All parameters in the model are linear, like:\n\\[ f(\\mathbf{x})=w_1x_1+w_2x_2+w_3x_3\\tag{1} \\]\nwhere the \\(w_n\\) where \\(n=1,2,3\\) are the parameters of the model, the output \\(f(\\mathbf{x})\\) can be written as \\(t\\) for 1-deminsional outputs (or \\(\\mathbf{t}\\) for multi-deminsional outputs).\n\\(f(\\mathbf{w})\\) is linear:\n\\[ \\begin{aligned} f(a\\cdot\\mathbf{w})\u0026amp;=aw_1x_1+aw_2x_2+aw_3x_3=a\\cdot f(\\mathbf{w}) \\\\ f(\\mathbf{w}+\\mathbf{v})\u0026amp;=(w_1+v_1)x_1+(w_2+v_2)x_2+(w_3+v_3)x_3\\\\ \u0026amp;=w_1x_1+v_1x_1+w_2x_2+v_2x_2+w_3x_3+v_3x_3\\\\ \u0026amp;=f(\\mathbf{w})+f(\\mathbf{v}) \\end{aligned}\\tag{2} \\]\nwhere \\(a\\) is a scalar, and \\(\\mathbf{v}\\) is in the same space with \\(\\mathbf{w}\\)\nQ.E.D\nThere is also another view that the linear property of models is also for \\(\\mathbf{x}\\), the input.\nBut the following model\n\\[ t=f(\\mathbf{x})=w_1\\log(x_1)+w_2\\sin(x_2)\\tag{3} \\]\nis a case of linear regression problem in our definition. But from the second point of view, it is not linear for inputs \\(\\mathbf{x}\\). However, this is not an unsolvable contradiction. If we use:\n\\[ y_1= \\log(x_1)\\\\ y_2= \\sin(x_2)\\tag{4} \\]\nto replace the \\(\\log\\) and \\(\\sin\\) in equation (3), we get again\n\\[ t=f(\\mathbf{y})=w_1y_1+w_2y_2\\tag{5} \\]\na linear operation for both input \\(\\mathbf{y}=\\begin{bmatrix}y_1\\;y_2\\end{bmatrix}^T\\) and parameters \\(\\mathbf{z}\\) .\nThe tranformation, equation(4), is called feature extraction. \\(\\mathbf{y}\\) is called features, and \\(\\log\\) and \\(\\sin\\) are called basis functions\nAn Example This example is taken from (James20131), It is about the sale between different kinds of advertisements. I downloaded the data set from http://faculty.marshall.usc.edu/gareth-james/ISL/data.html. It‚Äôs a CSV file, including 200 rows. Here I draw 3 pictures using ‚Äòmatplotlib‚Äô to make the data more visible. They are advertisements for ‚ÄòTV‚Äô, ‚ÄòRadio‚Äô, ‚ÄòNewspaper‚Äô to ‚ÄòSales‚Äô respectively.\nFrom these figures, we can find TV ads and Sales looks like having a stronger relationship than radio ads and sales. However, the Newspaper ads and Sales look independent.\nFor statistical learning, we should take statistical methods to investigate the relation in the data. And in machine learning, to a certain input, predicting an output is what we are concerned.\nWhy Linear Regression Linear regression has been used for more than 200 years, and it‚Äôs always been our first class of statistical learning or machine learning. Here we list 3 practical elements of linear regression, which are essential for the whole subject:\nIt is still working in some areas. Although more complicated models have been built, they could not be replaced totally. It is a good jump-off point to the other more feasible and adorable models, which may be an extension or generation of naive linear regression Linear regression is easy, so it is possible to be analyzed mathematically.  This is why linear regression is always our first step to learn machine learning and statistical learning. And by now, this works pretty well.\nA Probabilistic View Machine learning or statistical learning can be described from two different views - Bayesian and Frequentist. They both worked well for some different instances, but they also have their limitations. The Bayesian view of the linear regression will be talked about as well later.\nBayesian statisticians thought the input \\(\\mathbf{x}\\), the output \\(t\\), and the parameter \\(\\mathbf{w}\\) are all random variables, while the frequentist does not think so. Bayesian statisticians predict the unknown input \\(\\mathbf{x}_0\\) by forming the distribution \\(\\mathbb{P}(t_0|\\mathbf{x}_0)\\) and then sampling from it. To achieve this goal, we must build the \\(\\mathbb{P}(t|\\mathbf{x})\\) firstly. This is the modeling progress, or we can call it learning progress.\nReferences  James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. An introduction to statistical learning. Vol. 112. New York: springer, 2013.‚Ü©Ô∏é\n   ","permalink":"https://anthony-tan.com/deep_learning/introduction-to-linear-regression/","summary":"Preliminaries Linear Algebra(the concepts of space, vector) Calculus  What is Linear Regression Linear regression is a basic idea in statistical and machine learning based on the linear combination. And it was usually used to predict some responses to some inputs(predictors).\nMachine Learning and Statistical Learning Machine learning and statistical learning are similar but have some distinctions. In machine learning, models, regression models, or classification models, are used to predict the outputs of the new incoming inputs.","title":"An Introduction to Linear Regression"},{"content":"About Me Hi, I\u0026rsquo;m Anthony Tan(Ë∞≠Âçá). I am now living in Shenzhen, China. I\u0026rsquo;m a full-time computer vision algorithm engineer and a part-time individual reinforcement learning researcher. I have had a great interest in artificial intelligence since I watched the movie \u0026ldquo;Iron man\u0026rdquo; when I was a middle school student. And to get deeper into these subjects, I\u0026rsquo;d like to apply for a Ph.D. project on reinforcement learning in the following years. So far, I\u0026rsquo;ve learned and reviewed some papers that are necessary for reinforcement learning research, and some mathematics, like calculus, linear algebra, probability, and so on.\nHowever the bigger one in the picture is me, Tony, and the smaller one is my dog, Potato(He was too young to take a shower when we take the picture, and now he is no more a dirty puppyüòÄ)\nWhy the blogs These blogs here are used to simply explain what I have learned, according to the Feyman Technique. And blogging what I\u0026rsquo;ve just learned is the most important part of learning. The whole process is:\n Choosing a concept or theory I would like to know(collecting necessary materials )  Outlining what prior knowledge of this concept or theory Taking note of this prior knowledge   Try to explain the new theory to readers of the website without any new words and concepts in the theory (draft) Go back to the source and fill in the gap in understanding Simplify the explaining(rewrite and post)  What in blogs These blogs contain:\n Mathematics Neuroscience Algorithms  Deep Learning Reinforcement Learning    And some of these posts might also be represented by videos on my YouTube channel.\n","permalink":"https://anthony-tan.com/about/","summary":"About Me Hi, I\u0026rsquo;m Anthony Tan(Ë∞≠Âçá). I am now living in Shenzhen, China. I\u0026rsquo;m a full-time computer vision algorithm engineer and a part-time individual reinforcement learning researcher. I have had a great interest in artificial intelligence since I watched the movie \u0026ldquo;Iron man\u0026rdquo; when I was a middle school student. And to get deeper into these subjects, I\u0026rsquo;d like to apply for a Ph.D. project on reinforcement learning in the following years.","title":""}]